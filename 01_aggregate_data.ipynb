{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Ingestion and Aggregation\n",
    "\n",
    "This script pulls together data from multiple sources and combines them into the final sets used in the project for training and testing our models. The final datasets can be found in the following GoogleDrive: https://drive.google.com/drive/folders/13H72zfO7sIyxJa0QOCxKjza3dZhdyBhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/alex_fassone/Documents/MSc Statistics/ST456/Coursework/Project/Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIAR\n",
    "\n",
    "\n",
    "Information - https://datasets.activeloop.ai/docs/ml/datasets/liar-dataset/#:~:text=,email%20protected\n",
    "Data Download - https://www.cs.ucsb.edu/~william/data/liar_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_liar = file_path + '/Liar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load TSV into Pandas DataFrame\n",
    "def load_liar_split(filename):\n",
    "    path = os.path.join(file_path_liar, filename)\n",
    "    columns = [\n",
    "        \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job_title\",\n",
    "        \"state_info\", \"party_affiliation\", \"barely_true_counts\",\n",
    "        \"false_counts\", \"half_true_counts\", \"mostly_true_counts\",\n",
    "        \"pants_on_fire_counts\", \"context\"\n",
    "    ]\n",
    "    df = pd.read_csv(path, sep=\"\\t\", names=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_train_df = load_liar_split(\"train.tsv\")\n",
    "liar_test_df = load_liar_split(\"test.tsv\")\n",
    "liar_val_df = load_liar_split(\"valid.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1003830818544289"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liar_val_df)/(len(liar_test_df) + len(liar_train_df) + len(liar_val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id        label                                          statement  \\\n",
      "0   2635.json        false  Says the Annies List political group supports ...   \n",
      "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
      "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
      "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
      "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
      "\n",
      "                              subject         speaker             job_title  \\\n",
      "0                            abortion    dwayne-bohac  State representative   \n",
      "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
      "2                      foreign-policy    barack-obama             President   \n",
      "3                         health-care    blog-posting                   NaN   \n",
      "4                        economy,jobs   charlie-crist                   NaN   \n",
      "\n",
      "  state_info party_affiliation  barely_true_counts  false_counts  \\\n",
      "0      Texas        republican                 0.0           1.0   \n",
      "1   Virginia          democrat                 0.0           0.0   \n",
      "2   Illinois          democrat                70.0          71.0   \n",
      "3        NaN              none                 7.0          19.0   \n",
      "4    Florida          democrat                15.0           9.0   \n",
      "\n",
      "   half_true_counts  mostly_true_counts  pants_on_fire_counts  \\\n",
      "0               0.0                 0.0                   0.0   \n",
      "1               1.0                 1.0                   0.0   \n",
      "2             160.0               163.0                   9.0   \n",
      "3               3.0                 5.0                  44.0   \n",
      "4              20.0                19.0                   2.0   \n",
      "\n",
      "               context  \n",
      "0             a mailer  \n",
      "1      a floor speech.  \n",
      "2               Denver  \n",
      "3       a news release  \n",
      "4  an interview on CNN  \n"
     ]
    }
   ],
   "source": [
    "# Combine all three into a single DataFrame\n",
    "liar_combined_df = pd.concat([liar_train_df, liar_test_df, liar_val_df], ignore_index=True)\n",
    "\n",
    "# Show the first few rows\n",
    "print(liar_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label  binary_label\n",
      "0        false             0\n",
      "1    half-true             1\n",
      "2  mostly-true             1\n",
      "3        false             0\n",
      "4    half-true             1\n"
     ]
    }
   ],
   "source": [
    "# Define mapping function\n",
    "def binary_label(label):\n",
    "    if label in [\"true\", \"mostly-true\", \"half-true\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply it to create a new column\n",
    "liar_combined_df[\"binary_label\"] = liar_combined_df[\"label\"].apply(binary_label)\n",
    "\n",
    "# Show the result\n",
    "print(liar_combined_df[[\"label\", \"binary_label\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset                                               body  binary_label\n",
      "0    LIAR  Says the Annies List political group supports ...             0\n",
      "1    LIAR  When did the decline of coal start? It started...             1\n",
      "2    LIAR  Hillary Clinton agrees with John McCain \"by vo...             1\n",
      "3    LIAR  Health care reform legislation is likely to ma...             0\n",
      "4    LIAR  The economic turnaround started at the end of ...             1\n",
      "12791\n"
     ]
    }
   ],
   "source": [
    "# Add a new column called 'dataset' with constant value 'LIAR'\n",
    "liar_combined_df[\"dataset\"] = \"LIAR\"\n",
    "\n",
    "# Rename 'statement' to 'body'\n",
    "liar_combined_df.rename(columns={\"statement\": \"body\"}, inplace=True)\n",
    "\n",
    "# Create a new DataFrame with only the requested columns\n",
    "liar_simple_df = liar_combined_df[[\"dataset\", \"body\", \"binary_label\"]]\n",
    "\n",
    "# Show the result\n",
    "print(liar_simple_df.head())\n",
    "print(len(liar_simple_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIAR 2 \n",
    "\n",
    "Information - https://paperswithcode.com/dataset/liar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_liar_2 = file_path + '/Liar 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_liar_2_split(filename):\n",
    "    path = os.path.join(file_path_liar_2, filename)\n",
    "    columns = [\n",
    "        \"id\", \"label\", \"statement\", \"date\", \"subject\", \"speaker\", \"speaker_description\",\n",
    "        \"state_info\", \"true_counts\", \"mostly_true_counts\", \"half_true_counts\",  \n",
    "        \"mostly_false_counts\", \"false_counts\", \"pants_on_fire_counts\", \"context\", \"justification\"\n",
    "    ]\n",
    "    df = pd.read_csv(path, names=columns, header=0)  # Use default comma separator\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  label                                          statement  \\\n",
      "0  13847      5  90 percent of Americans \"support universal bac...   \n",
      "1  13411      1  Last year was one of the deadliest years ever ...   \n",
      "2  10882      0  Bernie Sanders's plan is \"to raise your taxes ...   \n",
      "3  20697      4  Voter ID is supported by an overwhelming major...   \n",
      "4   6095      2  Says Barack Obama \"robbed Medicare (of) $716 b...   \n",
      "\n",
      "               date                                            subject  \\\n",
      "0   October 2, 2017  government regulation;polls and public opinion...   \n",
      "1      May 19, 2017  after the fact;congress;criminal justice;histo...   \n",
      "2  October 28, 2015                                              taxes   \n",
      "3  December 8, 2021                                      voter id laws   \n",
      "4   August 12, 2012         federal budget;history;medicare;retirement   \n",
      "\n",
      "          speaker                                speaker_description  \\\n",
      "0     chris abele  Chris Abele is Milwaukee County Executive, a p...   \n",
      "1     thom tillis  Thom Tillis is a Republican who serves as U.S....   \n",
      "2  chris christie  Chris Christie announced June 6, 2023 that he ...   \n",
      "3      lee zeldin  Lee Zeldin is a Republican representing New Yo...   \n",
      "4     mitt romney  Mitt Romney is a U.S. senator from Utah. He ra...   \n",
      "\n",
      "       state_info  true_counts  mostly_true_counts  half_true_counts  \\\n",
      "0       wisconsin            1                   4                 5   \n",
      "1  north carolina            0                   2                 7   \n",
      "2        national           21                  20                27   \n",
      "3        new york            1                   2                 0   \n",
      "4        national           31                  33                58   \n",
      "\n",
      "   mostly_false_counts  false_counts  pants_on_fire_counts  \\\n",
      "0                    3             5                     2   \n",
      "1                    3             2                     0   \n",
      "2                   11            17                     8   \n",
      "3                    0             0                     0   \n",
      "4                   35            32                    19   \n",
      "\n",
      "                                             context  \\\n",
      "0                                            a tweet   \n",
      "1  a press release supporting the Back The Blue A...   \n",
      "2                                      Boulder, Colo   \n",
      "3                                            a Tweet   \n",
      "4                       an interview on \"60 Minutes\"   \n",
      "\n",
      "                                       justification  \n",
      "0  \"Universal\" is the term for background checks ...  \n",
      "1  Sen. Thom Tillis, a North Carolina Republican,...  \n",
      "2  Christie said that Sanders’s plan is \"to raise...  \n",
      "3  Zeldin claimed voter identification requiremen...  \n",
      "4  Romney said, \"There's only one president that ...  \n"
     ]
    }
   ],
   "source": [
    "liar_2_train_df = load_liar_2_split(\"train.csv\")\n",
    "liar_2_test_df = load_liar_2_split(\"test.csv\")\n",
    "liar_2_val_df = load_liar_2_split(\"valid.csv\")\n",
    "\n",
    "# Combine all three into a single DataFrame\n",
    "liar_2_combined_df = pd.concat([liar_2_train_df, liar_2_test_df, liar_2_val_df], ignore_index=True)\n",
    "\n",
    "# Show the first few rows\n",
    "print(liar_2_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  binary_label\n",
      "0      5             1\n",
      "1      1             0\n",
      "2      0             0\n",
      "3      4             1\n",
      "4      2             0\n"
     ]
    }
   ],
   "source": [
    "# Define mapping function\n",
    "def binary_label_liar_2(label):\n",
    "    if label in [0, 1, 2]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Apply it to create a new column\n",
    "liar_2_combined_df[\"binary_label\"] = liar_2_combined_df[\"label\"].apply(binary_label_liar_2)\n",
    "\n",
    "# Show the result\n",
    "print(liar_2_combined_df[[\"label\", \"binary_label\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset                                               body  binary_label  \\\n",
      "0  LIAR 2  90 percent of Americans \"support universal bac...             1   \n",
      "1  LIAR 2  Last year was one of the deadliest years ever ...             0   \n",
      "2  LIAR 2  Bernie Sanders's plan is \"to raise your taxes ...             0   \n",
      "3  LIAR 2  Voter ID is supported by an overwhelming major...             1   \n",
      "4  LIAR 2  Says Barack Obama \"robbed Medicare (of) $716 b...             0   \n",
      "\n",
      "   label  \n",
      "0      5  \n",
      "1      1  \n",
      "2      0  \n",
      "3      4  \n",
      "4      2  \n",
      "22962\n"
     ]
    }
   ],
   "source": [
    "# Add a new column called 'dataset' with constant value 'LIAR'\n",
    "liar_2_combined_df[\"dataset\"] = \"LIAR 2\"\n",
    "\n",
    "# Rename 'statement' to 'body'\n",
    "liar_2_combined_df.rename(columns={\"statement\": \"body\"}, inplace=True)\n",
    "\n",
    "# Create a new DataFrame with only the requested columns\n",
    "liar_2_simple_df = liar_2_combined_df[[\"dataset\", \"body\", \"binary_label\", \"label\"]]\n",
    "\n",
    "# Show the result\n",
    "print(liar_2_simple_df.head())\n",
    "print(len(liar_2_simple_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fakeddit\n",
    "\n",
    "Information - download here https://drive.google.com/drive/folders/1qYgeupmblRZDsUNaasJEtIJ6Sv-PEOlF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_fakeddit = file_path + '/Fakeddit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fakeddit_split(filename):\n",
    "    path = os.path.join(file_path_fakeddit, filename)\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                        clean_title  2_way_label\n",
      "0   awxhir  my walgreens offbrand mucinex was engraved wit...            1\n",
      "1  cvm5uy4                                                NaN            0\n",
      "2   98pbid                this concerned sink with a tiny hat            0\n",
      "3   6f2cy5      hackers leak emails from uae ambassador to us            1\n",
      "4  cc5cbon                                                NaN            0\n"
     ]
    }
   ],
   "source": [
    "fakeddit_train_df = load_fakeddit_split(\"all_train.tsv\")\n",
    "#fakeddit_test_df = load_fakeddit_split(\"all_test_public.tsv\")\n",
    "#fakeddit_val_df = load_fakeddit_split(\"all_validate.tsv\")\n",
    "\n",
    "# Combine all three into a single DataFrame\n",
    "fakeddit_combined_df = pd.concat([fakeddit_train_df], ignore_index=True)\n",
    "\n",
    "fakeddit_combined_df = fakeddit_combined_df[[\"id\", \"clean_title\", \"2_way_label\"]]\n",
    "\n",
    "# Show the first few rows\n",
    "print(fakeddit_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset                                              title  binary_label\n",
      "0  Fakeddit  my walgreens offbrand mucinex was engraved wit...             1\n",
      "2  Fakeddit                this concerned sink with a tiny hat             0\n",
      "3  Fakeddit      hackers leak emails from uae ambassador to us             1\n",
      "5  Fakeddit                     this flower in my neighborhood             1\n",
      "6  Fakeddit                           puppy taking in the view             1\n",
      "802789\n"
     ]
    }
   ],
   "source": [
    "# Add a new column called 'dataset' with constant value 'LIAR'\n",
    "fakeddit_combined_df[\"dataset\"] = \"Fakeddit\"\n",
    "\n",
    "# Rename 'statement' to 'body'\n",
    "fakeddit_combined_df.rename(columns={\"clean_title\": \"title\"}, inplace=True)\n",
    "fakeddit_combined_df.rename(columns={\"2_way_label\": \"binary_label\"}, inplace=True)\n",
    "\n",
    "# Create a new DataFrame with only the requested columns\n",
    "fakeddit_simple_df = fakeddit_combined_df[[\"dataset\", \"title\", \"binary_label\"]]\n",
    "\n",
    "fakeddit_simple_df = fakeddit_simple_df.dropna(subset=['title'])\n",
    "\n",
    "# Show the result\n",
    "print(fakeddit_simple_df.head())\n",
    "print(len(fakeddit_simple_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle 1 - Fake News Dataset\n",
    "\n",
    "Information - https://www.kaggle.com/datasets/abaghyangor/fake-news-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_kaggle_1_fake_news = file_path + '/Kaggle-1-Fake-News-Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kaggle_1_fake_news_split(filename):\n",
    "    path = os.path.join(file_path_kaggle_1_fake_news, filename)\n",
    "    columns = [\"title\", \"text\", \"subject\", \"date\"]\n",
    "    df = pd.read_csv(path, names=columns, header=0)  # Use default comma separator\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_1_fake_news_true_df = load_kaggle_1_fake_news_split(\"True.csv\")\n",
    "kaggle_1_fake_news_false_df = load_kaggle_1_fake_news_split(\"Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_1_fake_news_true_df[\"binary_label\"] = 1\n",
    "kaggle_1_fake_news_false_df[\"binary_label\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                dataset                                              title  \\\n",
      "0  Kaggle 1 - Fake News  As U.S. budget fight looms, Republicans flip t...   \n",
      "1  Kaggle 1 - Fake News  U.S. military to accept transgender recruits o...   \n",
      "2  Kaggle 1 - Fake News  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3  Kaggle 1 - Fake News  FBI Russia probe helped by Australian diplomat...   \n",
      "4  Kaggle 1 - Fake News  Trump wants Postal Service to charge 'much mor...   \n",
      "\n",
      "                                                body  binary_label  \n",
      "0  WASHINGTON (Reuters) - The head of a conservat...             1  \n",
      "1  WASHINGTON (Reuters) - Transgender people will...             1  \n",
      "2  WASHINGTON (Reuters) - The special counsel inv...             1  \n",
      "3  WASHINGTON (Reuters) - Trump campaign adviser ...             1  \n",
      "4  SEATTLE/WASHINGTON (Reuters) - President Donal...             1  \n",
      "44898\n"
     ]
    }
   ],
   "source": [
    "# Combine all three into a single DataFrame\n",
    "kaggle_1_fake_news_combined_df = pd.concat([kaggle_1_fake_news_true_df, kaggle_1_fake_news_false_df], ignore_index=True)\n",
    "\n",
    "# Rename 'text' to 'body'\n",
    "kaggle_1_fake_news_combined_df.rename(columns={\"text\": \"body\"}, inplace=True)\n",
    "\n",
    "kaggle_1_fake_news_combined_df[\"dataset\"] = 'Kaggle 1 - Fake News'\n",
    "\n",
    "# Create a new DataFrame with only the requested columns\n",
    "kaggle_1_fake_news_simple_df = kaggle_1_fake_news_combined_df[[\"dataset\", \"title\", \"body\", \"binary_label\"]]\n",
    "\n",
    "# Show the result\n",
    "print(kaggle_1_fake_news_simple_df.head())\n",
    "print(len(kaggle_1_fake_news_simple_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle 2 - News Project\n",
    "\n",
    "Information - https://www.kaggle.com/datasets/antonioskokiantonis/newscsv/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_kaggle_2_news_project = file_path + '/Kaggle-2-News-Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kaggle_2_news_project_split(filename):\n",
    "    path = os.path.join(file_path_kaggle_2_news_project, filename)\n",
    "    columns = [\"id\", \"title\", \"text\", \"label\"]\n",
    "    df = pd.read_csv(path, names=columns, header=0)  # Use default comma separator\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_2_news_project_df = load_kaggle_2_news_project_split(\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping function\n",
    "def binary_label_kaggle_2_news_project(label):\n",
    "    if label in [\"REAL\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply it to create a new column\n",
    "kaggle_2_news_project_df[\"binary_label\"] = kaggle_2_news_project_df[\"label\"].apply(binary_label_kaggle_2_news_project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   dataset                                              title  \\\n",
      "0  Kaggle 2 - News Project                       You Can Smell Hillary’s Fear   \n",
      "1  Kaggle 2 - News Project  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2  Kaggle 2 - News Project        Kerry to go to Paris in gesture of sympathy   \n",
      "3  Kaggle 2 - News Project  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4  Kaggle 2 - News Project   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                body  binary_label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...             0  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...             0  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...             1  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...             0  \n",
      "4  It's primary day in New York and front-runners...             1  \n",
      "6335\n"
     ]
    }
   ],
   "source": [
    "kaggle_2_news_project_df[\"dataset\"] = 'Kaggle 2 - News Project'\n",
    "\n",
    "kaggle_2_news_project_df.rename(columns={\"text\": \"body\"}, inplace=True)\n",
    "\n",
    "# Create a new DataFrame with only the requested columns\n",
    "kaggle_2_news_project_simple_df = kaggle_2_news_project_df[[\"dataset\", \"title\", \"body\", \"binary_label\"]]\n",
    "\n",
    "# Show the result\n",
    "print(kaggle_2_news_project_simple_df.head())\n",
    "print(len(kaggle_2_news_project_simple_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle 3 - Fake News Detection \n",
    "\n",
    "Information - https://www.kaggle.com/datasets/jruvika/fake-news-detection/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_kaggle_3_fake_news_detection = file_path + '/Kaggle-3-Fake-News-Detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kaggle_3_fake_news_detection_split(filename):\n",
    "    path = os.path.join(file_path_kaggle_3_fake_news_detection, filename)\n",
    "    columns = [\"url\", \"title\", \"body\", \"binary_label\"]\n",
    "    df = pd.read_csv(path, names=columns, header=0)  # Use default comma separator\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_3_fake_news_detection_df = load_kaggle_3_fake_news_detection_split('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_3_fake_news_detection_df['dataset'] = 'Kaggle 3 - Fake News Detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_3_fake_news_detection_simple_df = kaggle_3_fake_news_detection_df[[\"dataset\", \"title\", \"body\", \"binary_label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(\n",
    "    [\n",
    "        liar_2_simple_df,\n",
    "        fakeddit_simple_df, \n",
    "        kaggle_1_fake_news_simple_df,\n",
    "        kaggle_2_news_project_simple_df, \n",
    "        kaggle_3_fake_news_detection_simple_df\n",
    "    ], \n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Normalize unicode (remove accents)\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = combined_df[combined_df['title'].notna()].reset_index(drop=True)\n",
    "title_df = title_df[title_df['title'].str.split().str.len() > 1].reset_index(drop=True)\n",
    "title_df['text'] = title_df['title']\n",
    "title_df['text_clean'] = title_df['title'].apply(clean_text)\n",
    "title_df['title'] = True\n",
    "title_df['chunk_id'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = title_df[['dataset', 'text', 'text_clean', 'chunk_id', 'title', 'binary_label', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>this flower in my neighborhood</td>\n",
       "      <td>this flower in my neighborhood</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819511</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>Trends to Watch</td>\n",
       "      <td>trends to watch</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819512</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>Trump Jr. Is Soon To Give A 30-Minute Speech F...</td>\n",
       "      <td>trump jr is soon to give a 30minute speech for...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819513</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>Ron Paul on Trump, Anarchism &amp; the AltRight</td>\n",
       "      <td>ron paul on trump anarchism the altright</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819514</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>China to accept overseas trial data in bid to ...</td>\n",
       "      <td>china to accept overseas trial data in bid to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819515</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>Vice President Mike Pence Leaves NFL Game Beca...</td>\n",
       "      <td>vice president mike pence leaves nfl game beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819516 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dataset  \\\n",
       "0                             Fakeddit   \n",
       "1                             Fakeddit   \n",
       "2                             Fakeddit   \n",
       "3                             Fakeddit   \n",
       "4                             Fakeddit   \n",
       "...                                ...   \n",
       "819511  Kaggle 3 - Fake News Detection   \n",
       "819512  Kaggle 3 - Fake News Detection   \n",
       "819513  Kaggle 3 - Fake News Detection   \n",
       "819514  Kaggle 3 - Fake News Detection   \n",
       "819515  Kaggle 3 - Fake News Detection   \n",
       "\n",
       "                                                     text  \\\n",
       "0       my walgreens offbrand mucinex was engraved wit...   \n",
       "1                     this concerned sink with a tiny hat   \n",
       "2           hackers leak emails from uae ambassador to us   \n",
       "3                          this flower in my neighborhood   \n",
       "4                                puppy taking in the view   \n",
       "...                                                   ...   \n",
       "819511                                    Trends to Watch   \n",
       "819512  Trump Jr. Is Soon To Give A 30-Minute Speech F...   \n",
       "819513        Ron Paul on Trump, Anarchism & the AltRight   \n",
       "819514  China to accept overseas trial data in bid to ...   \n",
       "819515  Vice President Mike Pence Leaves NFL Game Beca...   \n",
       "\n",
       "                                               text_clean  chunk_id  title  \\\n",
       "0       my walgreens offbrand mucinex was engraved wit...         1   True   \n",
       "1                     this concerned sink with a tiny hat         1   True   \n",
       "2           hackers leak emails from uae ambassador to us         1   True   \n",
       "3                          this flower in my neighborhood         1   True   \n",
       "4                                puppy taking in the view         1   True   \n",
       "...                                                   ...       ...    ...   \n",
       "819511                                    trends to watch         1   True   \n",
       "819512  trump jr is soon to give a 30minute speech for...         1   True   \n",
       "819513           ron paul on trump anarchism the altright         1   True   \n",
       "819514  china to accept overseas trial data in bid to ...         1   True   \n",
       "819515  vice president mike pence leaves nfl game beca...         1   True   \n",
       "\n",
       "        binary_label  label  \n",
       "0                  1    NaN  \n",
       "1                  0    NaN  \n",
       "2                  1    NaN  \n",
       "3                  1    NaN  \n",
       "4                  1    NaN  \n",
       "...              ...    ...  \n",
       "819511             0    NaN  \n",
       "819512             0    NaN  \n",
       "819513             0    NaN  \n",
       "819514             1    NaN  \n",
       "819515             0    NaN  \n",
       "\n",
       "[819516 rows x 7 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>proportion_equals_1</th>\n",
       "      <th>proportion_over_64</th>\n",
       "      <th>proportion_over_128</th>\n",
       "      <th>avg_string_length</th>\n",
       "      <th>proportion_title_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>764299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.448797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kaggle 1 - Fake News</td>\n",
       "      <td>44888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.424612</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaggle 2 - News Project</td>\n",
       "      <td>6329</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.383631</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.684500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dataset  num_samples  proportion_equals_1  \\\n",
       "0                        Fakeddit       764299             0.000000   \n",
       "1            Kaggle 1 - Fake News        44888             0.000000   \n",
       "2         Kaggle 2 - News Project         6329             0.000158   \n",
       "3  Kaggle 3 - Fake News Detection         4000             0.000000   \n",
       "\n",
       "   proportion_over_64  proportion_over_128  avg_string_length  \\\n",
       "0            0.000031             0.000004           8.448797   \n",
       "1            0.000000             0.000000          12.424612   \n",
       "2            0.000000             0.000000          10.383631   \n",
       "3            0.000500             0.000000           9.684500   \n",
       "\n",
       "   proportion_title_present  \n",
       "0                       1.0  \n",
       "1                       1.0  \n",
       "2                       1.0  \n",
       "3                       1.0  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_summary_df = (\n",
    "    title_df\n",
    "    .groupby('dataset')\n",
    "    .agg(\n",
    "        num_samples = ('text_clean', 'count'),\n",
    "        proportion_equals_1 = ('text_clean', lambda x: (x.str.split().str.len() == 1).mean()),\n",
    "        proportion_over_64 = ('text_clean', lambda x: (x.str.split().str.len() > 64).mean()),\n",
    "        proportion_over_128 = ('text_clean', lambda x: (x.str.split().str.len() > 128).mean()),\n",
    "        avg_string_length = ('text_clean', lambda x: x.str.split().str.len().mean()),\n",
    "        proportion_title_present = ('title', lambda x: x.mean())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "title_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_df = combined_df[combined_df['body'].notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Kaggle 1 - Fake News              44898\n",
       "LIAR 2                            22962\n",
       "Kaggle 2 - News Project            6335\n",
       "Kaggle 3 - Fake News Detection     3988\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_df.value_counts('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=128):\n",
    "    tokens = text.split()  # simple whitespace tokenization\n",
    "    return [' '.join(tokens[i:i + chunk_size]) for i in range(0, len(tokens), chunk_size)]\n",
    "\n",
    "# Create a new DataFrame with one chunk per row\n",
    "def expand_chunks(df, text_column='body', chunk_size=128):\n",
    "    rows = []\n",
    "    for idx, row in df.iterrows():\n",
    "        chunks = split_text_into_chunks(row[text_column], chunk_size)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            new_row = row.copy()\n",
    "            new_row[text_column] = chunk\n",
    "            new_row['chunk_id'] = i + 1\n",
    "            rows.append(new_row)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "chunked_df = expand_chunks(body_df, text_column='body', chunk_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_df['text'] = chunked_df['body']\n",
    "chunked_df['text_clean'] = chunked_df['text'].apply(clean_text)\n",
    "chunked_df['title'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_df = chunked_df[['dataset', 'text', 'text_clean', 'chunk_id', 'title', 'binary_label', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIAR 2</td>\n",
       "      <td>90 percent of Americans \"support universal bac...</td>\n",
       "      <td>90 percent of americans support universal back...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIAR 2</td>\n",
       "      <td>Last year was one of the deadliest years ever ...</td>\n",
       "      <td>last year was one of the deadliest years ever ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIAR 2</td>\n",
       "      <td>Bernie Sanders's plan is \"to raise your taxes ...</td>\n",
       "      <td>bernie sanderss plan is to raise your taxes to...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIAR 2</td>\n",
       "      <td>Voter ID is supported by an overwhelming major...</td>\n",
       "      <td>voter id is supported by an overwhelming major...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIAR 2</td>\n",
       "      <td>Says Barack Obama \"robbed Medicare (of) $716 b...</td>\n",
       "      <td>says barack obama robbed medicare of 716 billi...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78182</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>the game with the second lady. The game is spe...</td>\n",
       "      <td>the game with the second lady the game is spec...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78182</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>their racial grievances and hatred of Presiden...</td>\n",
       "      <td>their racial grievances and hatred of presiden...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78182</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>expressed the following via Twitter: 52m Vice ...</td>\n",
       "      <td>expressed the following via twitter 52m vice p...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78182</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>our National Anthem. 11:08 AM – Oct 8, 2017 Pe...</td>\n",
       "      <td>our national anthem 1108 am oct 8 2017 pence w...</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78182</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>current events and commentary they can trust. ...</td>\n",
       "      <td>current events and commentary they can trust c...</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441877 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              dataset  \\\n",
       "0                              LIAR 2   \n",
       "1                              LIAR 2   \n",
       "2                              LIAR 2   \n",
       "3                              LIAR 2   \n",
       "4                              LIAR 2   \n",
       "...                               ...   \n",
       "78182  Kaggle 3 - Fake News Detection   \n",
       "78182  Kaggle 3 - Fake News Detection   \n",
       "78182  Kaggle 3 - Fake News Detection   \n",
       "78182  Kaggle 3 - Fake News Detection   \n",
       "78182  Kaggle 3 - Fake News Detection   \n",
       "\n",
       "                                                    text  \\\n",
       "0      90 percent of Americans \"support universal bac...   \n",
       "1      Last year was one of the deadliest years ever ...   \n",
       "2      Bernie Sanders's plan is \"to raise your taxes ...   \n",
       "3      Voter ID is supported by an overwhelming major...   \n",
       "4      Says Barack Obama \"robbed Medicare (of) $716 b...   \n",
       "...                                                  ...   \n",
       "78182  the game with the second lady. The game is spe...   \n",
       "78182  their racial grievances and hatred of Presiden...   \n",
       "78182  expressed the following via Twitter: 52m Vice ...   \n",
       "78182  our National Anthem. 11:08 AM – Oct 8, 2017 Pe...   \n",
       "78182  current events and commentary they can trust. ...   \n",
       "\n",
       "                                              text_clean  chunk_id  title  \\\n",
       "0      90 percent of americans support universal back...         1  False   \n",
       "1      last year was one of the deadliest years ever ...         1  False   \n",
       "2      bernie sanderss plan is to raise your taxes to...         1  False   \n",
       "3      voter id is supported by an overwhelming major...         1  False   \n",
       "4      says barack obama robbed medicare of 716 billi...         1  False   \n",
       "...                                                  ...       ...    ...   \n",
       "78182  the game with the second lady the game is spec...         6  False   \n",
       "78182  their racial grievances and hatred of presiden...         7  False   \n",
       "78182  expressed the following via twitter 52m vice p...         8  False   \n",
       "78182  our national anthem 1108 am oct 8 2017 pence w...         9  False   \n",
       "78182  current events and commentary they can trust c...        10  False   \n",
       "\n",
       "       binary_label  label  \n",
       "0                 1    5.0  \n",
       "1                 0    1.0  \n",
       "2                 0    0.0  \n",
       "3                 1    4.0  \n",
       "4                 0    2.0  \n",
       "...             ...    ...  \n",
       "78182             0    NaN  \n",
       "78182             0    NaN  \n",
       "78182             0    NaN  \n",
       "78182             0    NaN  \n",
       "78182             0    NaN  \n",
       "\n",
       "[441877 rows x 7 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reshape_df = pd.concat(\n",
    "    [\n",
    "        title_df,\n",
    "        chunked_df\n",
    "    ], \n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261393"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_reshape_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reshape_df = combined_reshape_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145518"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_reshape_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reshape_df['row_number'] = combined_reshape_df.groupby('dataset').cumcount()\n",
    "combined_reshape_df['id'] = combined_reshape_df['dataset'] + '_' + combined_reshape_df['row_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reshape_df = combined_reshape_df[['id', 'dataset', 'text', 'text_clean', 'chunk_id', 'title', 'binary_label', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fakeddit_0</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fakeddit_1</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakeddit_2</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fakeddit_3</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>this flower in my neighborhood</td>\n",
       "      <td>this flower in my neighborhood</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fakeddit_4</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261388</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28758</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>the game with the second lady. The game is spe...</td>\n",
       "      <td>the game with the second lady the game is spec...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261389</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28759</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>their racial grievances and hatred of Presiden...</td>\n",
       "      <td>their racial grievances and hatred of presiden...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261390</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28760</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>expressed the following via Twitter: 52m Vice ...</td>\n",
       "      <td>expressed the following via twitter 52m vice p...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261391</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28761</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>our National Anthem. 11:08 AM – Oct 8, 2017 Pe...</td>\n",
       "      <td>our national anthem 1108 am oct 8 2017 pence w...</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261392</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28762</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>current events and commentary they can trust. ...</td>\n",
       "      <td>current events and commentary they can trust c...</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1145518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id                         dataset  \\\n",
       "0                                  Fakeddit_0                        Fakeddit   \n",
       "1                                  Fakeddit_1                        Fakeddit   \n",
       "2                                  Fakeddit_2                        Fakeddit   \n",
       "3                                  Fakeddit_3                        Fakeddit   \n",
       "4                                  Fakeddit_4                        Fakeddit   \n",
       "...                                       ...                             ...   \n",
       "1261388  Kaggle 3 - Fake News Detection_28758  Kaggle 3 - Fake News Detection   \n",
       "1261389  Kaggle 3 - Fake News Detection_28759  Kaggle 3 - Fake News Detection   \n",
       "1261390  Kaggle 3 - Fake News Detection_28760  Kaggle 3 - Fake News Detection   \n",
       "1261391  Kaggle 3 - Fake News Detection_28761  Kaggle 3 - Fake News Detection   \n",
       "1261392  Kaggle 3 - Fake News Detection_28762  Kaggle 3 - Fake News Detection   \n",
       "\n",
       "                                                      text  \\\n",
       "0        my walgreens offbrand mucinex was engraved wit...   \n",
       "1                      this concerned sink with a tiny hat   \n",
       "2            hackers leak emails from uae ambassador to us   \n",
       "3                           this flower in my neighborhood   \n",
       "4                                 puppy taking in the view   \n",
       "...                                                    ...   \n",
       "1261388  the game with the second lady. The game is spe...   \n",
       "1261389  their racial grievances and hatred of Presiden...   \n",
       "1261390  expressed the following via Twitter: 52m Vice ...   \n",
       "1261391  our National Anthem. 11:08 AM – Oct 8, 2017 Pe...   \n",
       "1261392  current events and commentary they can trust. ...   \n",
       "\n",
       "                                                text_clean  chunk_id  title  \\\n",
       "0        my walgreens offbrand mucinex was engraved wit...         1   True   \n",
       "1                      this concerned sink with a tiny hat         1   True   \n",
       "2            hackers leak emails from uae ambassador to us         1   True   \n",
       "3                           this flower in my neighborhood         1   True   \n",
       "4                                 puppy taking in the view         1   True   \n",
       "...                                                    ...       ...    ...   \n",
       "1261388  the game with the second lady the game is spec...         6  False   \n",
       "1261389  their racial grievances and hatred of presiden...         7  False   \n",
       "1261390  expressed the following via twitter 52m vice p...         8  False   \n",
       "1261391  our national anthem 1108 am oct 8 2017 pence w...         9  False   \n",
       "1261392  current events and commentary they can trust c...        10  False   \n",
       "\n",
       "         binary_label  label  \n",
       "0                   1    NaN  \n",
       "1                   0    NaN  \n",
       "2                   1    NaN  \n",
       "3                   1    NaN  \n",
       "4                   1    NaN  \n",
       "...               ...    ...  \n",
       "1261388             0    NaN  \n",
       "1261389             0    NaN  \n",
       "1261390             0    NaN  \n",
       "1261391             0    NaN  \n",
       "1261392             0    NaN  \n",
       "\n",
       "[1145518 rows x 8 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_reshape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>proportion_true</th>\n",
       "      <th>proportion_over_64</th>\n",
       "      <th>proportion_over_128</th>\n",
       "      <th>avg_string_length</th>\n",
       "      <th>proportion_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>707590</td>\n",
       "      <td>0.538449</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.721854</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kaggle 1 - Fake News</td>\n",
       "      <td>300913</td>\n",
       "      <td>0.527079</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.060778</td>\n",
       "      <td>0.128685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaggle 2 - News Project</td>\n",
       "      <td>85316</td>\n",
       "      <td>0.558336</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.413897</td>\n",
       "      <td>0.073257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>28763</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.305636</td>\n",
       "      <td>0.098251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIAR 2</td>\n",
       "      <td>22936</td>\n",
       "      <td>0.423396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.608825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dataset  num_samples  proportion_true  \\\n",
       "0                        Fakeddit       707590         0.538449   \n",
       "1            Kaggle 1 - Fake News       300913         0.527079   \n",
       "2         Kaggle 2 - News Project        85316         0.558336   \n",
       "3  Kaggle 3 - Fake News Detection        28763         0.621528   \n",
       "4                          LIAR 2        22936         0.423396   \n",
       "\n",
       "   proportion_over_64  proportion_over_128  avg_string_length  \\\n",
       "0            0.000034             0.000004           8.721854   \n",
       "1            0.000003             0.000000          53.060778   \n",
       "2            0.000141             0.000000          57.413897   \n",
       "3            0.000104             0.000000          55.305636   \n",
       "4            0.000000             0.000000          17.608825   \n",
       "\n",
       "   proportion_title  \n",
       "0          1.000000  \n",
       "1          0.128685  \n",
       "2          0.073257  \n",
       "3          0.098251  \n",
       "4          0.000000  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = (\n",
    "    combined_reshape_df\n",
    "    .groupby('dataset')\n",
    "    .agg(\n",
    "        num_samples = ('text_clean', 'count'),\n",
    "        proportion_true = ('binary_label', lambda x: (x == 1).mean()),\n",
    "        proportion_over_64 = ('text_clean', lambda x: (x.str.split().str.len() > 64).mean()),\n",
    "        proportion_over_128 = ('text_clean', lambda x: (x.str.split().str.len() > 128).mean()),\n",
    "        avg_string_length = ('text_clean', lambda x: x.str.split().str.len().mean()),\n",
    "        proportion_title = ('title', lambda x: x.mean())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/36/2pfmkvbd5ks6224y4yd_dyjh0000gn/T/ipykernel_14879/2422094238.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_reshape_df = combined_reshape_df.groupby('dataset').apply(lambda x: x.sample(n=sample_size, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "sample_size = 20000\n",
    "sampled_reshape_df = combined_reshape_df.groupby('dataset').apply(lambda x: x.sample(n=sample_size, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_df, test_df = train_test_split(sampled_reshape_df, test_size=test_fraction, random_state=42, stratify=sampled_reshape_df[['dataset', 'binary_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "LIAR 2                            4000\n",
       "Kaggle 2 - News Project           4000\n",
       "Kaggle 3 - Fake News Detection    4000\n",
       "Fakeddit                          4000\n",
       "Kaggle 1 - Fake News              4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "1    10667\n",
       "0     9333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['binary_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df = combined_reshape_df[~combined_reshape_df['id'].isin(test_df['id'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_reshape_df) - len(combined_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fakeddit_0</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fakeddit_1</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>this concerned sink with a tiny hat</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakeddit_2</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>hackers leak emails from uae ambassador to us</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fakeddit_3</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>this flower in my neighborhood</td>\n",
       "      <td>this flower in my neighborhood</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fakeddit_4</td>\n",
       "      <td>Fakeddit</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>puppy taking in the view</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261387</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28757</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>around our Flag and everything that unites us....</td>\n",
       "      <td>around our flag and everything that unites us ...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261388</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28758</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>the game with the second lady. The game is spe...</td>\n",
       "      <td>the game with the second lady the game is spec...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261389</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28759</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>their racial grievances and hatred of Presiden...</td>\n",
       "      <td>their racial grievances and hatred of presiden...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261390</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28760</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>expressed the following via Twitter: 52m Vice ...</td>\n",
       "      <td>expressed the following via twitter 52m vice p...</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261391</th>\n",
       "      <td>Kaggle 3 - Fake News Detection_28761</td>\n",
       "      <td>Kaggle 3 - Fake News Detection</td>\n",
       "      <td>our National Anthem. 11:08 AM – Oct 8, 2017 Pe...</td>\n",
       "      <td>our national anthem 1108 am oct 8 2017 pence w...</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id                         dataset  \\\n",
       "0                                  Fakeddit_0                        Fakeddit   \n",
       "1                                  Fakeddit_1                        Fakeddit   \n",
       "2                                  Fakeddit_2                        Fakeddit   \n",
       "3                                  Fakeddit_3                        Fakeddit   \n",
       "4                                  Fakeddit_4                        Fakeddit   \n",
       "...                                       ...                             ...   \n",
       "1261387  Kaggle 3 - Fake News Detection_28757  Kaggle 3 - Fake News Detection   \n",
       "1261388  Kaggle 3 - Fake News Detection_28758  Kaggle 3 - Fake News Detection   \n",
       "1261389  Kaggle 3 - Fake News Detection_28759  Kaggle 3 - Fake News Detection   \n",
       "1261390  Kaggle 3 - Fake News Detection_28760  Kaggle 3 - Fake News Detection   \n",
       "1261391  Kaggle 3 - Fake News Detection_28761  Kaggle 3 - Fake News Detection   \n",
       "\n",
       "                                                      text  \\\n",
       "0        my walgreens offbrand mucinex was engraved wit...   \n",
       "1                      this concerned sink with a tiny hat   \n",
       "2            hackers leak emails from uae ambassador to us   \n",
       "3                           this flower in my neighborhood   \n",
       "4                                 puppy taking in the view   \n",
       "...                                                    ...   \n",
       "1261387  around our Flag and everything that unites us....   \n",
       "1261388  the game with the second lady. The game is spe...   \n",
       "1261389  their racial grievances and hatred of Presiden...   \n",
       "1261390  expressed the following via Twitter: 52m Vice ...   \n",
       "1261391  our National Anthem. 11:08 AM – Oct 8, 2017 Pe...   \n",
       "\n",
       "                                                text_clean  chunk_id  title  \\\n",
       "0        my walgreens offbrand mucinex was engraved wit...         1   True   \n",
       "1                      this concerned sink with a tiny hat         1   True   \n",
       "2            hackers leak emails from uae ambassador to us         1   True   \n",
       "3                           this flower in my neighborhood         1   True   \n",
       "4                                 puppy taking in the view         1   True   \n",
       "...                                                    ...       ...    ...   \n",
       "1261387  around our flag and everything that unites us ...         5  False   \n",
       "1261388  the game with the second lady the game is spec...         6  False   \n",
       "1261389  their racial grievances and hatred of presiden...         7  False   \n",
       "1261390  expressed the following via twitter 52m vice p...         8  False   \n",
       "1261391  our national anthem 1108 am oct 8 2017 pence w...         9  False   \n",
       "\n",
       "         binary_label  label  \n",
       "0                   1    NaN  \n",
       "1                   0    NaN  \n",
       "2                   1    NaN  \n",
       "3                   1    NaN  \n",
       "4                   1    NaN  \n",
       "...               ...    ...  \n",
       "1261387             0    NaN  \n",
       "1261388             0    NaN  \n",
       "1261389             0    NaN  \n",
       "1261390             0    NaN  \n",
       "1261391             0    NaN  \n",
       "\n",
       "[1125518 rows x 8 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_df.to_csv(file_path + \"/Combined/combined_train_df_2.csv\", index=False)\n",
    "sample_train_df.to_csv(file_path + \"/Combined/sample_train_df_2.csv\", index=False)\n",
    "test_df.to_csv(file_path + \"/Combined/test_df_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Generated Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Generated New Dataset\n",
    "\n",
    "Information: https://github.com/navid-aub/News-Dataset/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_llm_news_dataset = file_path + '/LLM Generated News Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm_news_dataset_split(filename):\n",
    "    path = os.path.join(file_path_llm_news_dataset, filename)\n",
    "    df = pd.read_csv(path, header=0)  # Use default comma separator\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_dataset_chatgpt_df = load_llm_news_dataset_split('chatgpt.csv')\n",
    "llm_news_dataset_llama2_7b_df = load_llm_news_dataset_split('llama2_7b.csv')\n",
    "llm_news_dataset_llama2_13b_df = load_llm_news_dataset_split('llama2_13b.csv')\n",
    "llm_news_dataset_mistral_7b_df = load_llm_news_dataset_split('mistral_7b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_dataset_chatgpt_df['model'] = 'GPT3.5'\n",
    "llm_news_dataset_llama2_7b_df['model'] = 'Llama2 7b'\n",
    "llm_news_dataset_llama2_13b_df['model'] = 'Llama2 13b'\n",
    "llm_news_dataset_mistral_7b_df['model'] = 'Mistral 7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_df = pd.concat(\n",
    "    [\n",
    "        llm_news_dataset_chatgpt_df,\n",
    "        llm_news_dataset_llama2_7b_df, \n",
    "        llm_news_dataset_llama2_13b_df, \n",
    "        llm_news_dataset_mistral_7b_df\n",
    "    ], \n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>title</th>\n",
       "      <th>main</th>\n",
       "      <th>words</th>\n",
       "      <th>topic</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>expanded</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_expanded</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbsnews.com</td>\n",
       "      <td>Trump holds \"celebration of American flag\" in ...</td>\n",
       "      <td>Instead of holding a Super Bowl champion cerem...</td>\n",
       "      <td>368</td>\n",
       "      <td>sports</td>\n",
       "      <td>President Trump changed plans for the Super Bo...</td>\n",
       "      <td>event, presumably coming from disappointed Eag...</td>\n",
       "      <td>President Trump rescinded the Philadelphia Eag...</td>\n",
       "      <td>**\"President Trump Hosts 'Celebration of Ameri...</td>\n",
       "      <td>GPT3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apnews.com</td>\n",
       "      <td>Pope observes usual Ash Wednesday customs in t...</td>\n",
       "      <td>VATICAN CITY (AP)  Pope Francis celebrated th...</td>\n",
       "      <td>688</td>\n",
       "      <td>['history', 'religion']</td>\n",
       "      <td>VATICAN CITY (AP) – Pope Francis observed the ...</td>\n",
       "      <td>crisis that has affected many parts of the wor...</td>\n",
       "      <td>Headline: Pope Francis Leads Traditional Ash W...</td>\n",
       "      <td>**Pope Francis Leads Traditional Ash Wednesday...</td>\n",
       "      <td>GPT3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>Jim Molan likely to face challenge by moderate...</td>\n",
       "      <td>Conservative Jim Molans expected return to th...</td>\n",
       "      <td>380</td>\n",
       "      <td>['politics', 'government']</td>\n",
       "      <td>Conservative Senator Jim Molan is anticipated ...</td>\n",
       "      <td>Sorry, but I can't continue with the specific ...</td>\n",
       "      <td>The anticipated return of Conservative Jim Mol...</td>\n",
       "      <td>**Title: Battle Brews as Moderates Challenge C...</td>\n",
       "      <td>GPT3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>Scott Morrison sworn in as Australia's 30th pr...</td>\n",
       "      <td>23 Aug 2018 17.52 EDT OK, this is significant....</td>\n",
       "      <td>1000</td>\n",
       "      <td>['politics', 'government']</td>\n",
       "      <td>News Article Rephrased:\\n\\n**August 23, 2018 |...</td>\n",
       "      <td>Certainly, here's an extended and completed ve...</td>\n",
       "      <td>Date: August 23, 2018\\n\\nHeadlines:\\n1. Libera...</td>\n",
       "      <td>**Ongoing Turmoil in Liberal Party: Leadership...</td>\n",
       "      <td>GPT3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reuters.com</td>\n",
       "      <td>French clergy sexually abused over 200,000 chi...</td>\n",
       "      <td>Summary Investigation finds estimated 216,000 ...</td>\n",
       "      <td>857</td>\n",
       "      <td>['history', 'religion']</td>\n",
       "      <td>Investigation Reveals Shocking Scale of Child ...</td>\n",
       "      <td>to investigate allegations of abuse within the...</td>\n",
       "      <td>A recent investigation into the French Catholi...</td>\n",
       "      <td>**Title: French Catholic Church Report Reveals...</td>\n",
       "      <td>GPT3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>aljazeera.com</td>\n",
       "      <td>Australia prison abuse could violate UN tortur...</td>\n",
       "      <td>The use of restraints and tear gas on juvenile...</td>\n",
       "      <td>423</td>\n",
       "      <td>['social culture', 'civil rights']</td>\n",
       "      <td>Footage of Australian aboriginal children in ...</td>\n",
       "      <td>\"a very serious situation\" and that the use o...</td>\n",
       "      <td>A UN official, Juan Mendez, has expressed conc...</td>\n",
       "      <td>Title: UN Official Expressed Concerns over All...</td>\n",
       "      <td>Mistral 7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>cbsnews.com</td>\n",
       "      <td>Adylkuzz hack, called larger than WannaCry, sl...</td>\n",
       "      <td>Many computers and servers around the world wh...</td>\n",
       "      <td>756</td>\n",
       "      <td>['science', 'information technology']</td>\n",
       "      <td>A security firm, Proofpoint, has revealed that...</td>\n",
       "      <td>other illicit goods. The surge in demand for ...</td>\n",
       "      <td>A security company, Proofpoint, revealed that ...</td>\n",
       "      <td>Title: WannaCry Ransomware Attack Surprisingly...</td>\n",
       "      <td>Mistral 7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>cbsnews.com</td>\n",
       "      <td>Brad Pitt and Angelina Jolie to wed this weekend?</td>\n",
       "      <td>Brad Pitt, left, and Angelina Jolie arrive at ...</td>\n",
       "      <td>362</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>(CBS News) speculation swirls around Brad Pit...</td>\n",
       "      <td>that wedding preparations have been in full s...</td>\n",
       "      <td>Reports have surfaced that Brad Pitt and Angel...</td>\n",
       "      <td>Title: Brad Pitt and Angelina Jolie's Upcoming...</td>\n",
       "      <td>Mistral 7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>Rag'n'Bone Man wins 2017 Brits critics' choice...</td>\n",
       "      <td>Sussex hip-hop bluesman RagnBone Man has bee...</td>\n",
       "      <td>375</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>Rag'n'Bone Man, the Sussex-based hip-hop blues...</td>\n",
       "      <td>has spent years honing his craft as a perform...</td>\n",
       "      <td>Rory Graham, known as Rag'n'Bone Man, was name...</td>\n",
       "      <td>Title: Rag'n'Bone Man Wins Brits Critics Choic...</td>\n",
       "      <td>Mistral 7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>From Good Girl to Gangsta: Evolution of Miley ...</td>\n",
       "      <td>June 13, 2013 -- intro: Miley Cyrus has been ...</td>\n",
       "      <td>475</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>[June 13, 2013] - Miley Cyrus Unveils New Loo...</td>\n",
       "      <td>strum his guitar on the set of \"Hannah Montan...</td>\n",
       "      <td>Miley Cyrus, a 20-year-old singer-actress, mad...</td>\n",
       "      <td>Miley Cyrus Shocks Fans with New \"Gangsta\" Loo...</td>\n",
       "      <td>Mistral 7b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                agency                                              title  \\\n",
       "0          cbsnews.com  Trump holds \"celebration of American flag\" in ...   \n",
       "1           apnews.com  Pope observes usual Ash Wednesday customs in t...   \n",
       "2      theguardian.com  Jim Molan likely to face challenge by moderate...   \n",
       "3      theguardian.com  Scott Morrison sworn in as Australia's 30th pr...   \n",
       "4          reuters.com  French clergy sexually abused over 200,000 chi...   \n",
       "...                ...                                                ...   \n",
       "11995    aljazeera.com  Australia prison abuse could violate UN tortur...   \n",
       "11996      cbsnews.com  Adylkuzz hack, called larger than WannaCry, sl...   \n",
       "11997      cbsnews.com  Brad Pitt and Angelina Jolie to wed this weekend?   \n",
       "11998  theguardian.com  Rag'n'Bone Man wins 2017 Brits critics' choice...   \n",
       "11999   abcnews.go.com  From Good Girl to Gangsta: Evolution of Miley ...   \n",
       "\n",
       "                                                    main  words  \\\n",
       "0      Instead of holding a Super Bowl champion cerem...    368   \n",
       "1      VATICAN CITY (AP)  Pope Francis celebrated th...    688   \n",
       "2      Conservative Jim Molans expected return to th...    380   \n",
       "3      23 Aug 2018 17.52 EDT OK, this is significant....   1000   \n",
       "4      Summary Investigation finds estimated 216,000 ...    857   \n",
       "...                                                  ...    ...   \n",
       "11995  The use of restraints and tear gas on juvenile...    423   \n",
       "11996  Many computers and servers around the world wh...    756   \n",
       "11997  Brad Pitt, left, and Angelina Jolie arrive at ...    362   \n",
       "11998  Sussex hip-hop bluesman RagnBone Man has bee...    375   \n",
       "11999  June 13, 2013 -- intro: Miley Cyrus has been ...    475   \n",
       "\n",
       "                                       topic  \\\n",
       "0                                     sports   \n",
       "1                    ['history', 'religion']   \n",
       "2                 ['politics', 'government']   \n",
       "3                 ['politics', 'government']   \n",
       "4                    ['history', 'religion']   \n",
       "...                                      ...   \n",
       "11995     ['social culture', 'civil rights']   \n",
       "11996  ['science', 'information technology']   \n",
       "11997                              celebrity   \n",
       "11998                              celebrity   \n",
       "11999                              celebrity   \n",
       "\n",
       "                                                rephrase  \\\n",
       "0      President Trump changed plans for the Super Bo...   \n",
       "1      VATICAN CITY (AP) – Pope Francis observed the ...   \n",
       "2      Conservative Senator Jim Molan is anticipated ...   \n",
       "3      News Article Rephrased:\\n\\n**August 23, 2018 |...   \n",
       "4      Investigation Reveals Shocking Scale of Child ...   \n",
       "...                                                  ...   \n",
       "11995   Footage of Australian aboriginal children in ...   \n",
       "11996  A security firm, Proofpoint, has revealed that...   \n",
       "11997   (CBS News) speculation swirls around Brad Pit...   \n",
       "11998  Rag'n'Bone Man, the Sussex-based hip-hop blues...   \n",
       "11999   [June 13, 2013] - Miley Cyrus Unveils New Loo...   \n",
       "\n",
       "                                                expanded  \\\n",
       "0      event, presumably coming from disappointed Eag...   \n",
       "1      crisis that has affected many parts of the wor...   \n",
       "2      Sorry, but I can't continue with the specific ...   \n",
       "3      Certainly, here's an extended and completed ve...   \n",
       "4      to investigate allegations of abuse within the...   \n",
       "...                                                  ...   \n",
       "11995   \"a very serious situation\" and that the use o...   \n",
       "11996   other illicit goods. The surge in demand for ...   \n",
       "11997   that wedding preparations have been in full s...   \n",
       "11998   has spent years honing his craft as a perform...   \n",
       "11999   strum his guitar on the set of \"Hannah Montan...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      President Trump rescinded the Philadelphia Eag...   \n",
       "1      Headline: Pope Francis Leads Traditional Ash W...   \n",
       "2      The anticipated return of Conservative Jim Mol...   \n",
       "3      Date: August 23, 2018\\n\\nHeadlines:\\n1. Libera...   \n",
       "4      A recent investigation into the French Catholi...   \n",
       "...                                                  ...   \n",
       "11995  A UN official, Juan Mendez, has expressed conc...   \n",
       "11996  A security company, Proofpoint, revealed that ...   \n",
       "11997  Reports have surfaced that Brad Pitt and Angel...   \n",
       "11998  Rory Graham, known as Rag'n'Bone Man, was name...   \n",
       "11999  Miley Cyrus, a 20-year-old singer-actress, mad...   \n",
       "\n",
       "                                        summary_expanded       model  \n",
       "0      **\"President Trump Hosts 'Celebration of Ameri...      GPT3.5  \n",
       "1      **Pope Francis Leads Traditional Ash Wednesday...      GPT3.5  \n",
       "2      **Title: Battle Brews as Moderates Challenge C...      GPT3.5  \n",
       "3      **Ongoing Turmoil in Liberal Party: Leadership...      GPT3.5  \n",
       "4      **Title: French Catholic Church Report Reveals...      GPT3.5  \n",
       "...                                                  ...         ...  \n",
       "11995  Title: UN Official Expressed Concerns over All...  Mistral 7b  \n",
       "11996  Title: WannaCry Ransomware Attack Surprisingly...  Mistral 7b  \n",
       "11997  Title: Brad Pitt and Angelina Jolie's Upcoming...  Mistral 7b  \n",
       "11998  Title: Rag'n'Bone Man Wins Brits Critics Choic...  Mistral 7b  \n",
       "11999  Miley Cyrus Shocks Fans with New \"Gangsta\" Loo...  Mistral 7b  \n",
       "\n",
       "[12000 rows x 10 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_long_df = llm_news_df.melt(\n",
    "    id_vars=['model'],  # no ID columns specified, unless you have other columns you want to keep\n",
    "    value_vars=['main', 'title', 'rephrase', 'expanded', 'summary', 'summary_expanded'],\n",
    "    var_name='type', \n",
    "    value_name='text'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_long_df = llm_news_long_df[llm_news_long_df['text'].notna()]\n",
    "llm_news_long_df = llm_news_long_df[llm_news_long_df['text'].apply(lambda x: isinstance(x, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "main                12000\n",
       "title               12000\n",
       "summary             11996\n",
       "summary_expanded    11954\n",
       "rephrase            11924\n",
       "expanded            11838\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_long_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary_label column\n",
    "llm_news_long_df['binary_label'] = llm_news_long_df['type'].apply(\n",
    "    lambda x: 1 if x in ['title', 'main'] else 0\n",
    ")\n",
    "\n",
    "llm_news_long_df['title'] = llm_news_long_df['type'].apply(\n",
    "    lambda x: True if x in ['title'] else False\n",
    ")\n",
    "\n",
    "# Only set model to NaN where type is 'title' or 'main'\n",
    "mask = llm_news_long_df['type'].isin(['title', 'main'])\n",
    "llm_news_long_df.loc[mask, 'model'] = np.nan\n",
    "\n",
    "llm_news_long_df['dataset'] = 'LLM News Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>title</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>Instead of holding a Super Bowl champion cerem...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>VATICAN CITY (AP)  Pope Francis celebrated th...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>Conservative Jim Molans expected return to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>23 Aug 2018 17.52 EDT OK, this is significant....</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>Summary Investigation finds estimated 216,000 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71995</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>Title: UN Official Expressed Concerns over All...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71996</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>Title: WannaCry Ransomware Attack Surprisingly...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71997</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>Title: Brad Pitt and Angelina Jolie's Upcoming...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71998</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>Title: Rag'n'Bone Man Wins Brits Critics Choic...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>Miley Cyrus Shocks Fans with New \"Gangsta\" Loo...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71712 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            model              type  \\\n",
       "0             NaN              main   \n",
       "1             NaN              main   \n",
       "2             NaN              main   \n",
       "3             NaN              main   \n",
       "4             NaN              main   \n",
       "...           ...               ...   \n",
       "71995  Mistral 7b  summary_expanded   \n",
       "71996  Mistral 7b  summary_expanded   \n",
       "71997  Mistral 7b  summary_expanded   \n",
       "71998  Mistral 7b  summary_expanded   \n",
       "71999  Mistral 7b  summary_expanded   \n",
       "\n",
       "                                                    text  binary_label  title  \\\n",
       "0      Instead of holding a Super Bowl champion cerem...             1  False   \n",
       "1      VATICAN CITY (AP)  Pope Francis celebrated th...             1  False   \n",
       "2      Conservative Jim Molans expected return to th...             1  False   \n",
       "3      23 Aug 2018 17.52 EDT OK, this is significant....             1  False   \n",
       "4      Summary Investigation finds estimated 216,000 ...             1  False   \n",
       "...                                                  ...           ...    ...   \n",
       "71995  Title: UN Official Expressed Concerns over All...             0  False   \n",
       "71996  Title: WannaCry Ransomware Attack Surprisingly...             0  False   \n",
       "71997  Title: Brad Pitt and Angelina Jolie's Upcoming...             0  False   \n",
       "71998  Title: Rag'n'Bone Man Wins Brits Critics Choic...             0  False   \n",
       "71999  Miley Cyrus Shocks Fans with New \"Gangsta\" Loo...             0  False   \n",
       "\n",
       "                dataset  \n",
       "0      LLM News Dataset  \n",
       "1      LLM News Dataset  \n",
       "2      LLM News Dataset  \n",
       "3      LLM News Dataset  \n",
       "4      LLM News Dataset  \n",
       "...                 ...  \n",
       "71995  LLM News Dataset  \n",
       "71996  LLM News Dataset  \n",
       "71997  LLM News Dataset  \n",
       "71998  LLM News Dataset  \n",
       "71999  LLM News Dataset  \n",
       "\n",
       "[71712 rows x 6 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_long_chunked_df = expand_chunks(llm_news_long_df, text_column='text', chunk_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_long_chunked_df['text_clean'] = llm_news_long_chunked_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_long_chunked_df['row_number'] = llm_news_long_chunked_df.groupby('dataset').cumcount()\n",
    "llm_news_long_chunked_df['id'] = llm_news_long_chunked_df['dataset'] + '_' + llm_news_long_chunked_df['row_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_news_long_chunked_df = llm_news_long_chunked_df[['id', 'dataset', 'model', 'type', 'text', 'text_clean', 'chunk_id', 'title', 'binary_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM News Dataset_0</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>Instead of holding a Super Bowl champion cerem...</td>\n",
       "      <td>instead of holding a super bowl champion cerem...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM News Dataset_1</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>at the event. He disinvited the Eagles from th...</td>\n",
       "      <td>at the event he disinvited the eagles from the...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM News Dataset_2</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>was unclear if those jeers were directed at Mr...</td>\n",
       "      <td>was unclear if those jeers were directed at mr...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM News Dataset_3</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>love our home, and our country has never done ...</td>\n",
       "      <td>love our home and our country has never done b...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM News Dataset_4</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main</td>\n",
       "      <td>tells CBS News that fewer than 10 players comm...</td>\n",
       "      <td>tells cbs news that fewer than 10 players comm...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>LLM News Dataset_477804</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>pixie cut and began sporting edgier clothes an...</td>\n",
       "      <td>pixie cut and began sporting edgier clothes an...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>LLM News Dataset_477805</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>been compared to rapper styles, has left some ...</td>\n",
       "      <td>been compared to rapper styles has left some f...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>LLM News Dataset_477806</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>have been circulating the internet, have spark...</td>\n",
       "      <td>have been circulating the internet have sparke...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>LLM News Dataset_477807</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>way of her creativity and self-expression. Cyr...</td>\n",
       "      <td>way of her creativity and selfexpression cyrus...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71999</th>\n",
       "      <td>LLM News Dataset_477808</td>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>[insert link]. And for Cyrus' response to Aman...</td>\n",
       "      <td>insert link and for cyrus response to amanda b...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477809 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id           dataset       model  \\\n",
       "0           LLM News Dataset_0  LLM News Dataset         NaN   \n",
       "0           LLM News Dataset_1  LLM News Dataset         NaN   \n",
       "0           LLM News Dataset_2  LLM News Dataset         NaN   \n",
       "0           LLM News Dataset_3  LLM News Dataset         NaN   \n",
       "0           LLM News Dataset_4  LLM News Dataset         NaN   \n",
       "...                        ...               ...         ...   \n",
       "71999  LLM News Dataset_477804  LLM News Dataset  Mistral 7b   \n",
       "71999  LLM News Dataset_477805  LLM News Dataset  Mistral 7b   \n",
       "71999  LLM News Dataset_477806  LLM News Dataset  Mistral 7b   \n",
       "71999  LLM News Dataset_477807  LLM News Dataset  Mistral 7b   \n",
       "71999  LLM News Dataset_477808  LLM News Dataset  Mistral 7b   \n",
       "\n",
       "                   type                                               text  \\\n",
       "0                  main  Instead of holding a Super Bowl champion cerem...   \n",
       "0                  main  at the event. He disinvited the Eagles from th...   \n",
       "0                  main  was unclear if those jeers were directed at Mr...   \n",
       "0                  main  love our home, and our country has never done ...   \n",
       "0                  main  tells CBS News that fewer than 10 players comm...   \n",
       "...                 ...                                                ...   \n",
       "71999  summary_expanded  pixie cut and began sporting edgier clothes an...   \n",
       "71999  summary_expanded  been compared to rapper styles, has left some ...   \n",
       "71999  summary_expanded  have been circulating the internet, have spark...   \n",
       "71999  summary_expanded  way of her creativity and self-expression. Cyr...   \n",
       "71999  summary_expanded  [insert link]. And for Cyrus' response to Aman...   \n",
       "\n",
       "                                              text_clean  chunk_id  title  \\\n",
       "0      instead of holding a super bowl champion cerem...         1  False   \n",
       "0      at the event he disinvited the eagles from the...         2  False   \n",
       "0      was unclear if those jeers were directed at mr...         3  False   \n",
       "0      love our home and our country has never done b...         4  False   \n",
       "0      tells cbs news that fewer than 10 players comm...         5  False   \n",
       "...                                                  ...       ...    ...   \n",
       "71999  pixie cut and began sporting edgier clothes an...         3  False   \n",
       "71999  been compared to rapper styles has left some f...         4  False   \n",
       "71999  have been circulating the internet have sparke...         5  False   \n",
       "71999  way of her creativity and selfexpression cyrus...         6  False   \n",
       "71999  insert link and for cyrus response to amanda b...         7  False   \n",
       "\n",
       "       binary_label  \n",
       "0                 1  \n",
       "0                 1  \n",
       "0                 1  \n",
       "0                 1  \n",
       "0                 1  \n",
       "...             ...  \n",
       "71999             0  \n",
       "71999             0  \n",
       "71999             0  \n",
       "71999             0  \n",
       "71999             0  \n",
       "\n",
       "[477809 rows x 9 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_long_chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "GPT3.5        89109\n",
       "Mistral 7b    84859\n",
       "Llama2 7b     81687\n",
       "Llama2 13b    81078\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_long_chunked_df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "main                129076\n",
       "expanded            108312\n",
       "summary_expanded    101938\n",
       "rephrase             80531\n",
       "summary              45952\n",
       "title                12000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_long_chunked_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>proportion_true</th>\n",
       "      <th>proportion_over_64</th>\n",
       "      <th>proportion_over_128</th>\n",
       "      <th>avg_string_length</th>\n",
       "      <th>proportion_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM News Dataset</td>\n",
       "      <td>477809</td>\n",
       "      <td>0.295256</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.551557</td>\n",
       "      <td>0.025115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset  num_samples  proportion_true  proportion_over_64  \\\n",
       "0  LLM News Dataset       477809         0.295256            0.000004   \n",
       "\n",
       "   proportion_over_128  avg_string_length  proportion_title  \n",
       "0                  0.0          58.551557          0.025115  "
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_news_summary_df = (\n",
    "    llm_news_long_chunked_df\n",
    "    .groupby('dataset')\n",
    "    .agg(\n",
    "        num_samples = ('text_clean', 'count'),\n",
    "        proportion_true = ('binary_label', lambda x: (x == 1).mean()),\n",
    "        proportion_over_64 = ('text_clean', lambda x: (x.str.split().str.len() > 64).mean()),\n",
    "        proportion_over_128 = ('text_clean', lambda x: (x.str.split().str.len() > 128).mean()),\n",
    "        avg_string_length = ('text_clean', lambda x: x.str.split().str.len().mean()),\n",
    "        proportion_title = ('title', lambda x: x.mean())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "llm_news_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2\n",
    "llm_train_df, llm_test_df = train_test_split(llm_news_long_chunked_df, test_size=test_fraction, random_state=42, stratify=llm_news_long_chunked_df[['dataset', 'type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "GPT3.5        17752\n",
       "Mistral 7b    17062\n",
       "Llama2 7b     16363\n",
       "Llama2 13b    16170\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_test_df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "main                25815\n",
       "expanded            21663\n",
       "summary_expanded    20388\n",
       "rephrase            16106\n",
       "summary              9190\n",
       "title                2400\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_test_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>expanded</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>rephrase</td>\n",
       "      <td>4896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>summary</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT3.5</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>5068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama2 13b</td>\n",
       "      <td>expanded</td>\n",
       "      <td>5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama2 13b</td>\n",
       "      <td>rephrase</td>\n",
       "      <td>3512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama2 13b</td>\n",
       "      <td>summary</td>\n",
       "      <td>1873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama2 13b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>4992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama2 7b</td>\n",
       "      <td>expanded</td>\n",
       "      <td>5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama2 7b</td>\n",
       "      <td>rephrase</td>\n",
       "      <td>3392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama2 7b</td>\n",
       "      <td>summary</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Llama2 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>5105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>expanded</td>\n",
       "      <td>5289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>rephrase</td>\n",
       "      <td>4306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mistral 7b</td>\n",
       "      <td>summary_expanded</td>\n",
       "      <td>5223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model              type  count\n",
       "0       GPT3.5          expanded   5026\n",
       "1       GPT3.5          rephrase   4896\n",
       "2       GPT3.5           summary   2762\n",
       "3       GPT3.5  summary_expanded   5068\n",
       "4   Llama2 13b          expanded   5793\n",
       "5   Llama2 13b          rephrase   3512\n",
       "6   Llama2 13b           summary   1873\n",
       "7   Llama2 13b  summary_expanded   4992\n",
       "8    Llama2 7b          expanded   5555\n",
       "9    Llama2 7b          rephrase   3392\n",
       "10   Llama2 7b           summary   2311\n",
       "11   Llama2 7b  summary_expanded   5105\n",
       "12  Mistral 7b          expanded   5289\n",
       "13  Mistral 7b          rephrase   4306\n",
       "14  Mistral 7b           summary   2244\n",
       "15  Mistral 7b  summary_expanded   5223"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_test_df.groupby(['model', 'type']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_train_df.to_csv(file_path + \"/Combined/llm_train_df.csv\", index=False)\n",
    "llm_test_df.to_csv(file_path + \"/Combined/llm_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MegaFake LLM Generated Dataset \n",
    "\n",
    "Information: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5095309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_megafake = file_path + '/MegaFake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_megafake_dataset_split(filename):\n",
    "    path = os.path.join(file_path_megafake, filename)\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index').reset_index()\n",
    "    df = df.rename(columns={'index': 'example_id'})  # Rename the key column if needed\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "megafake_style_based_fake = load_megafake_dataset_split('megafake-1_style_based_fake.json')\n",
    "megafake_content_based_fake = load_megafake_dataset_split('megafake-2_content_based_fake.json')\n",
    "megafake_integration_based_fake = load_megafake_dataset_split('megafake-3_integration_based_fake_tn200.json')\n",
    "megafake_story_based_fake = load_megafake_dataset_split('megafake-4_story_based_fake.json')\n",
    "megafake_style_based_legitimate = load_megafake_dataset_split('megafake-5_style_based_legitimate.json')\n",
    "megafake_integration_based_legitimate = load_megafake_dataset_split('megafake-7_integration_based_legitimate_tn300.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_words</th>\n",
       "      <th>doc_1_id</th>\n",
       "      <th>doc_1_label</th>\n",
       "      <th>doc_1_text</th>\n",
       "      <th>doc_2_id</th>\n",
       "      <th>doc_2_label</th>\n",
       "      <th>doc_2_text</th>\n",
       "      <th>generated_label</th>\n",
       "      <th>generated_text_t01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>megafake-916405_megafake-905417</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, movie, Awards, like, say, act, mother, ...</td>\n",
       "      <td>megafake-916405</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Tonya Harding says the Olympics have changed s...</td>\n",
       "      <td>megafake-905417</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Story highlights Margulies talks about life af...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Tonya Harding, the first American woman to suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>megafake-908189_megafake-905948</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, movie, Awards, like, say, act, mother, ...</td>\n",
       "      <td>megafake-908189</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Will Perry Wright live on?  Alexander Skarsgar...</td>\n",
       "      <td>megafake-905948</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Diane Kruger talked about her career-defining ...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>In the first season of the hit HBO drama Big L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>megafake-902348_megafake-905156</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, movie, Awards, like, say, act, mother, ...</td>\n",
       "      <td>megafake-902348</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Jane Fonda celebrated a big milestone that, th...</td>\n",
       "      <td>megafake-905156</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Tonya Harding threatened to walk out of an int...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>In a recent interview with People, Academy Awa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megafake-910383_megafake-892738</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, movie, Awards, like, say, act, mother, ...</td>\n",
       "      <td>megafake-910383</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Alexander Skarsgård’s Big Little Lies characte...</td>\n",
       "      <td>megafake-892738</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>If you spent a few years wondering when Michel...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Alexander Skarsgård, who played the menacing P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>megafake-934497_megafake-907416</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, movie, Awards, like, say, act, mother, ...</td>\n",
       "      <td>megafake-934497</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Jane Fonda is busier than she’s ever been at 8...</td>\n",
       "      <td>megafake-907416</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Jane Fonda and Lily Tomlin appear on Bravo’s W...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>In a recent interview with Ellen DeGeneres, Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>megafake-881465_megafake-908331</td>\n",
       "      <td>297</td>\n",
       "      <td>[Reply, Thread, Link,    , Parent, Richie, lik...</td>\n",
       "      <td>megafake-881465</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>American model and media personality (born 199...</td>\n",
       "      <td>megafake-908331</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>OMG 20 YEARS? Fuck me. :[ I love this movie, e...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Sofia Richie is an American social media perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>megafake-914648_megafake-845722</td>\n",
       "      <td>297</td>\n",
       "      <td>[Reply, Thread, Link,    , Parent, Richie, lik...</td>\n",
       "      <td>megafake-914648</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>American model and media personality (born 199...</td>\n",
       "      <td>megafake-845722</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>CBS’ Two-part true-crime series “The Case Of: ...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Sofia Richie is an American social media perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>megafake-869136_megafake-861559</td>\n",
       "      <td>297</td>\n",
       "      <td>[Reply, Thread, Link,    , Parent, Richie, lik...</td>\n",
       "      <td>megafake-869136</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>A photo of Nicolas Cage is sweeping the intern...</td>\n",
       "      <td>megafake-861559</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Here are 4 times humans actually competed agai...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Nicholas Cage, the Oscar-winning actor, has ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>megafake-868810_megafake-929852</td>\n",
       "      <td>297</td>\n",
       "      <td>[Reply, Thread, Link,    , Parent, Richie, lik...</td>\n",
       "      <td>megafake-868810</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Here are 4 times humans actually competed agai...</td>\n",
       "      <td>megafake-929852</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Fleetwood Mac Drags Lindsey Buckingham After O...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>In a highly anticipated event, Discovery Chann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>megafake-869377_megafake-925204</td>\n",
       "      <td>297</td>\n",
       "      <td>[Reply, Thread, Link,    , Parent, Richie, lik...</td>\n",
       "      <td>megafake-869377</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Update: Michael Phelps defended his Shark Week...</td>\n",
       "      <td>megafake-925204</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Here Comes the Sun  Herb Kohl, former U.S. sen...</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>Michael Phelps, the Olympic gold medalist, par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5926 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           example_id  topic_id  \\\n",
       "0     megafake-916405_megafake-905417         0   \n",
       "1     megafake-908189_megafake-905948         0   \n",
       "2     megafake-902348_megafake-905156         0   \n",
       "3     megafake-910383_megafake-892738         0   \n",
       "4     megafake-934497_megafake-907416         0   \n",
       "...                               ...       ...   \n",
       "5921  megafake-881465_megafake-908331       297   \n",
       "5922  megafake-914648_megafake-845722       297   \n",
       "5923  megafake-869136_megafake-861559       297   \n",
       "5924  megafake-868810_megafake-929852       297   \n",
       "5925  megafake-869377_megafake-925204       297   \n",
       "\n",
       "                                            topic_words         doc_1_id  \\\n",
       "0     [work, movie, Awards, like, say, act, mother, ...  megafake-916405   \n",
       "1     [work, movie, Awards, like, say, act, mother, ...  megafake-908189   \n",
       "2     [work, movie, Awards, like, say, act, mother, ...  megafake-902348   \n",
       "3     [work, movie, Awards, like, say, act, mother, ...  megafake-910383   \n",
       "4     [work, movie, Awards, like, say, act, mother, ...  megafake-934497   \n",
       "...                                                 ...              ...   \n",
       "5921  [Reply, Thread, Link,    , Parent, Richie, lik...  megafake-881465   \n",
       "5922  [Reply, Thread, Link,    , Parent, Richie, lik...  megafake-914648   \n",
       "5923  [Reply, Thread, Link,    , Parent, Richie, lik...  megafake-869136   \n",
       "5924  [Reply, Thread, Link,    , Parent, Richie, lik...  megafake-868810   \n",
       "5925  [Reply, Thread, Link,    , Parent, Richie, lik...  megafake-869377   \n",
       "\n",
       "     doc_1_label                                         doc_1_text  \\\n",
       "0     legitimate  Tonya Harding says the Olympics have changed s...   \n",
       "1     legitimate  Will Perry Wright live on?  Alexander Skarsgar...   \n",
       "2     legitimate  Jane Fonda celebrated a big milestone that, th...   \n",
       "3     legitimate  Alexander Skarsgård’s Big Little Lies characte...   \n",
       "4     legitimate  Jane Fonda is busier than she’s ever been at 8...   \n",
       "...          ...                                                ...   \n",
       "5921  legitimate  American model and media personality (born 199...   \n",
       "5922  legitimate  American model and media personality (born 199...   \n",
       "5923  legitimate  A photo of Nicolas Cage is sweeping the intern...   \n",
       "5924  legitimate  Here are 4 times humans actually competed agai...   \n",
       "5925  legitimate  Update: Michael Phelps defended his Shark Week...   \n",
       "\n",
       "             doc_2_id doc_2_label  \\\n",
       "0     megafake-905417  legitimate   \n",
       "1     megafake-905948  legitimate   \n",
       "2     megafake-905156  legitimate   \n",
       "3     megafake-892738  legitimate   \n",
       "4     megafake-907416  legitimate   \n",
       "...               ...         ...   \n",
       "5921  megafake-908331  legitimate   \n",
       "5922  megafake-845722  legitimate   \n",
       "5923  megafake-861559  legitimate   \n",
       "5924  megafake-929852  legitimate   \n",
       "5925  megafake-925204  legitimate   \n",
       "\n",
       "                                             doc_2_text generated_label  \\\n",
       "0     Story highlights Margulies talks about life af...      legitimate   \n",
       "1     Diane Kruger talked about her career-defining ...      legitimate   \n",
       "2     Tonya Harding threatened to walk out of an int...      legitimate   \n",
       "3     If you spent a few years wondering when Michel...      legitimate   \n",
       "4     Jane Fonda and Lily Tomlin appear on Bravo’s W...      legitimate   \n",
       "...                                                 ...             ...   \n",
       "5921  OMG 20 YEARS? Fuck me. :[ I love this movie, e...      legitimate   \n",
       "5922  CBS’ Two-part true-crime series “The Case Of: ...      legitimate   \n",
       "5923  Here are 4 times humans actually competed agai...      legitimate   \n",
       "5924  Fleetwood Mac Drags Lindsey Buckingham After O...      legitimate   \n",
       "5925  Here Comes the Sun  Herb Kohl, former U.S. sen...      legitimate   \n",
       "\n",
       "                                     generated_text_t01  \n",
       "0     Tonya Harding, the first American woman to suc...  \n",
       "1     In the first season of the hit HBO drama Big L...  \n",
       "2     In a recent interview with People, Academy Awa...  \n",
       "3     Alexander Skarsgård, who played the menacing P...  \n",
       "4     In a recent interview with Ellen DeGeneres, Ja...  \n",
       "...                                                 ...  \n",
       "5921  Sofia Richie is an American social media perso...  \n",
       "5922  Sofia Richie is an American social media perso...  \n",
       "5923  Nicholas Cage, the Oscar-winning actor, has ca...  \n",
       "5924  In a highly anticipated event, Discovery Chann...  \n",
       "5925  Michael Phelps, the Olympic gold medalist, par...  \n",
       "\n",
       "[5926 rows x 11 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_integration_based_legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def megafake_raw_data_reshape(df, generation_technique, fake, text_column = \"generated_text\"):\n",
    "\n",
    "    output_df = df.copy()\n",
    "\n",
    "    output_df['dataset'] = 'MegaFake'\n",
    "    output_df['generation_technique'] = generation_technique\n",
    "    output_df['title'] = False\n",
    "\n",
    "    if fake == True:\n",
    "        output_df['binary_label'] = 0\n",
    "    else:\n",
    "        output_df['binary_label'] = 1\n",
    "\n",
    "    output_df.rename(columns={text_column: 'text'}, inplace=True)\n",
    "\n",
    "    output_df = output_df[['dataset', 'generation_technique', 'text', 'title', 'binary_label']]\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "megafake_style_based_fake_reshape = megafake_raw_data_reshape(megafake_style_based_fake, 'style based', True, \"generated_text\")\n",
    "megafake_content_based_fake_reshape = megafake_raw_data_reshape(megafake_content_based_fake, 'content based', True, \"generated_text_glm4\")\n",
    "megafake_integration_based_fake_reshape = megafake_raw_data_reshape(megafake_integration_based_fake, 'integration based', True, \"generated_text\")\n",
    "megafake_story_based_fake_reshape = megafake_raw_data_reshape(megafake_story_based_fake, 'story based', True, \"generated_text\")\n",
    "megafake_style_based_legitimate_reshape = megafake_raw_data_reshape(megafake_style_based_legitimate, 'style based', False, \"generated_text_t015\")\n",
    "megafake_integration_based_legitimate_reshape = megafake_raw_data_reshape(megafake_integration_based_legitimate, 'integration based', False, \"generated_text_t01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45788"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(megafake_style_based_fake_reshape) + len(megafake_content_based_fake_reshape) + len(megafake_integration_based_fake_reshape) + len(megafake_story_based_fake_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>generation_technique</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>Tonya Harding, the first American woman to suc...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>In the first season of the hit HBO drama Big L...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>In a recent interview with People, Academy Awa...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>Alexander Skarsgård, who played the menacing P...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>In a recent interview with Ellen DeGeneres, Ja...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>Sofia Richie is an American social media perso...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>Sofia Richie is an American social media perso...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>Nicholas Cage, the Oscar-winning actor, has ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>In a highly anticipated event, Discovery Chann...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>integration based</td>\n",
       "      <td>Michael Phelps, the Olympic gold medalist, par...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5926 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset generation_technique  \\\n",
       "0     MegaFake    integration based   \n",
       "1     MegaFake    integration based   \n",
       "2     MegaFake    integration based   \n",
       "3     MegaFake    integration based   \n",
       "4     MegaFake    integration based   \n",
       "...        ...                  ...   \n",
       "5921  MegaFake    integration based   \n",
       "5922  MegaFake    integration based   \n",
       "5923  MegaFake    integration based   \n",
       "5924  MegaFake    integration based   \n",
       "5925  MegaFake    integration based   \n",
       "\n",
       "                                                   text  title  binary_label  \n",
       "0     Tonya Harding, the first American woman to suc...  False             1  \n",
       "1     In the first season of the hit HBO drama Big L...  False             1  \n",
       "2     In a recent interview with People, Academy Awa...  False             1  \n",
       "3     Alexander Skarsgård, who played the menacing P...  False             1  \n",
       "4     In a recent interview with Ellen DeGeneres, Ja...  False             1  \n",
       "...                                                 ...    ...           ...  \n",
       "5921  Sofia Richie is an American social media perso...  False             1  \n",
       "5922  Sofia Richie is an American social media perso...  False             1  \n",
       "5923  Nicholas Cage, the Oscar-winning actor, has ca...  False             1  \n",
       "5924  In a highly anticipated event, Discovery Chann...  False             1  \n",
       "5925  Michael Phelps, the Olympic gold medalist, par...  False             1  \n",
       "\n",
       "[5926 rows x 5 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_integration_based_legitimate_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "megafake_df = pd.concat(\n",
    "    [\n",
    "        megafake_style_based_fake_reshape,\n",
    "        megafake_content_based_fake_reshape, \n",
    "        megafake_integration_based_fake_reshape, \n",
    "        megafake_story_based_fake_reshape, \n",
    "        #megafake_style_based_legitimate_reshape,\n",
    "        #megafake_integration_based_legitimate_reshape\n",
    "    ], \n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "megafake_df = megafake_df[megafake_df['text'].notna()]\n",
    "megafake_df = megafake_df[megafake_df['text'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "megafake_df = expand_chunks(megafake_df, text_column='text', chunk_size=64)\n",
    "megafake_df['text_clean'] = megafake_df['text'].apply(clean_text)\n",
    "\n",
    "megafake_df['row_number'] = megafake_df.groupby('dataset').cumcount()\n",
    "megafake_df['id'] = megafake_df['dataset'] + '_' + megafake_df['row_number'].astype(str)\n",
    "\n",
    "megafake_df = megafake_df[['id', 'dataset', 'generation_technique', 'text', 'text_clean', 'chunk_id', 'title', 'binary_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>generation_technique</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>title</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MegaFake_0</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>style based</td>\n",
       "      <td>According to recent reports, Miley Cyrus and L...</td>\n",
       "      <td>according to recent reports miley cyrus and li...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MegaFake_1</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>style based</td>\n",
       "      <td>the property. The source of the report, who re...</td>\n",
       "      <td>the property the source of the report who requ...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MegaFake_2</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>style based</td>\n",
       "      <td>at the ceremony, along with siblings Noah, Tra...</td>\n",
       "      <td>at the ceremony along with siblings noah trace...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MegaFake_3</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>style based</td>\n",
       "      <td>to have a baby.</td>\n",
       "      <td>to have a baby</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MegaFake_4</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>style based</td>\n",
       "      <td>Paris Jackson and Cara Delevingne were seen to...</td>\n",
       "      <td>paris jackson and cara delevingne were seen to...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45786</th>\n",
       "      <td>MegaFake_203525</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>story based</td>\n",
       "      <td>help and that she should be surrounded by peop...</td>\n",
       "      <td>help and that she should be surrounded by peop...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45787</th>\n",
       "      <td>MegaFake_203526</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>story based</td>\n",
       "      <td>Kylie Jenner, the 24-year-old reality TV star ...</td>\n",
       "      <td>kylie jenner the 24yearold reality tv star and...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45787</th>\n",
       "      <td>MegaFake_203527</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>story based</td>\n",
       "      <td>butterflies has been a source of concern for h...</td>\n",
       "      <td>butterflies has been a source of concern for h...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45787</th>\n",
       "      <td>MegaFake_203528</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>story based</td>\n",
       "      <td>and confidence. She has become one of the most...</td>\n",
       "      <td>and confidence she has become one of the most ...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45787</th>\n",
       "      <td>MegaFake_203529</td>\n",
       "      <td>MegaFake</td>\n",
       "      <td>story based</td>\n",
       "      <td>for her brand. Regardless of the motivation, J...</td>\n",
       "      <td>for her brand regardless of the motivation jen...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203530 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   dataset generation_technique  \\\n",
       "0           MegaFake_0  MegaFake          style based   \n",
       "0           MegaFake_1  MegaFake          style based   \n",
       "0           MegaFake_2  MegaFake          style based   \n",
       "0           MegaFake_3  MegaFake          style based   \n",
       "1           MegaFake_4  MegaFake          style based   \n",
       "...                ...       ...                  ...   \n",
       "45786  MegaFake_203525  MegaFake          story based   \n",
       "45787  MegaFake_203526  MegaFake          story based   \n",
       "45787  MegaFake_203527  MegaFake          story based   \n",
       "45787  MegaFake_203528  MegaFake          story based   \n",
       "45787  MegaFake_203529  MegaFake          story based   \n",
       "\n",
       "                                                    text  \\\n",
       "0      According to recent reports, Miley Cyrus and L...   \n",
       "0      the property. The source of the report, who re...   \n",
       "0      at the ceremony, along with siblings Noah, Tra...   \n",
       "0                                        to have a baby.   \n",
       "1      Paris Jackson and Cara Delevingne were seen to...   \n",
       "...                                                  ...   \n",
       "45786  help and that she should be surrounded by peop...   \n",
       "45787  Kylie Jenner, the 24-year-old reality TV star ...   \n",
       "45787  butterflies has been a source of concern for h...   \n",
       "45787  and confidence. She has become one of the most...   \n",
       "45787  for her brand. Regardless of the motivation, J...   \n",
       "\n",
       "                                              text_clean  chunk_id  title  \\\n",
       "0      according to recent reports miley cyrus and li...         1  False   \n",
       "0      the property the source of the report who requ...         2  False   \n",
       "0      at the ceremony along with siblings noah trace...         3  False   \n",
       "0                                         to have a baby         4  False   \n",
       "1      paris jackson and cara delevingne were seen to...         1  False   \n",
       "...                                                  ...       ...    ...   \n",
       "45786  help and that she should be surrounded by peop...         6  False   \n",
       "45787  kylie jenner the 24yearold reality tv star and...         1  False   \n",
       "45787  butterflies has been a source of concern for h...         2  False   \n",
       "45787  and confidence she has become one of the most ...         3  False   \n",
       "45787  for her brand regardless of the motivation jen...         4  False   \n",
       "\n",
       "       binary_label  \n",
       "0                 0  \n",
       "0                 0  \n",
       "0                 0  \n",
       "0                 0  \n",
       "1                 0  \n",
       "...             ...  \n",
       "45786             0  \n",
       "45787             0  \n",
       "45787             0  \n",
       "45787             0  \n",
       "45787             0  \n",
       "\n",
       "[203530 rows x 8 columns]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation_technique\n",
       "style based          111414\n",
       "content based         66979\n",
       "story based           55173\n",
       "integration based     36527\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_df.value_counts('generation_technique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generation_technique</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content based</td>\n",
       "      <td>0</td>\n",
       "      <td>66979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>integration based</td>\n",
       "      <td>0</td>\n",
       "      <td>12550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>integration based</td>\n",
       "      <td>1</td>\n",
       "      <td>23977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story based</td>\n",
       "      <td>0</td>\n",
       "      <td>55173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>style based</td>\n",
       "      <td>0</td>\n",
       "      <td>68828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>style based</td>\n",
       "      <td>1</td>\n",
       "      <td>42586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  generation_technique  binary_label  count\n",
       "0        content based             0  66979\n",
       "1    integration based             0  12550\n",
       "2    integration based             1  23977\n",
       "3          story based             0  55173\n",
       "4          style based             0  68828\n",
       "5          style based             1  42586"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_df.groupby(['generation_technique', 'binary_label']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>proportion_true</th>\n",
       "      <th>proportion_over_64</th>\n",
       "      <th>proportion_over_128</th>\n",
       "      <th>avg_string_length</th>\n",
       "      <th>proportion_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MegaFake</td>\n",
       "      <td>203530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.744721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset  num_samples  proportion_true  proportion_over_64  \\\n",
       "0  MegaFake       203530              0.0            0.000005   \n",
       "\n",
       "   proportion_over_128  avg_string_length  proportion_title  \n",
       "0                  0.0          56.744721               0.0  "
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_summary_df = (\n",
    "    megafake_df\n",
    "    .groupby('dataset')\n",
    "    .agg(\n",
    "        num_samples = ('text_clean', 'count'),\n",
    "        proportion_true = ('binary_label', lambda x: (x == 1).mean()),\n",
    "        proportion_over_64 = ('text_clean', lambda x: (x.str.split().str.len() > 64).mean()),\n",
    "        proportion_over_128 = ('text_clean', lambda x: (x.str.split().str.len() > 128).mean()),\n",
    "        avg_string_length = ('text_clean', lambda x: x.str.split().str.len().mean()),\n",
    "        proportion_title = ('title', lambda x: x.mean())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "megafake_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fraction = 0.2\n",
    "megafake_train_df, megafake_test_df = train_test_split(megafake_df, test_size=test_fraction, random_state=42, stratify=megafake_df[['generation_technique', 'binary_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation_technique\n",
       "style based          22283\n",
       "content based        13396\n",
       "story based          11035\n",
       "integration based     7305\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_test_df.value_counts('generation_technique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generation_technique</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content based</td>\n",
       "      <td>0</td>\n",
       "      <td>13396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>integration based</td>\n",
       "      <td>0</td>\n",
       "      <td>2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>integration based</td>\n",
       "      <td>1</td>\n",
       "      <td>4795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story based</td>\n",
       "      <td>0</td>\n",
       "      <td>11035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>style based</td>\n",
       "      <td>0</td>\n",
       "      <td>13766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>style based</td>\n",
       "      <td>1</td>\n",
       "      <td>8517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  generation_technique  binary_label  count\n",
       "0        content based             0  13396\n",
       "1    integration based             0   2510\n",
       "2    integration based             1   4795\n",
       "3          story based             0  11035\n",
       "4          style based             0  13766\n",
       "5          style based             1   8517"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megafake_test_df.groupby(['generation_technique', 'binary_label']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "megafake_test_df.to_csv(file_path + \"/Combined/megafake_test_df.csv\", index=False)\n",
    "megafake_train_df.to_csv(file_path + \"/Combined/megafake_train_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
