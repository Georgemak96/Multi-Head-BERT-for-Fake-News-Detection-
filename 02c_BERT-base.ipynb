{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aaff321",
   "metadata": {},
   "source": [
    "### This script implements BERT-base training only on human-generated dataset. LIAR 2 middle category is excluded from training. Additionally, we test on the \"LLM Fake News Dataset\" ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c8f305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bde48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('combined_train_df_2.csv.zip','r') as zip:\n",
    "    with zip.open('combined_train_df_2.csv') as f:\n",
    "        train = pd.read_csv(f,encoding='ISO-8859-1')\n",
    "\n",
    "with zipfile.ZipFile('test_df_2.csv.zip','r') as zip:\n",
    "    with zip.open('test_df_2.csv') as f:\n",
    "        test = pd.read_csv(f,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610317b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing third category (Half-True)\n",
    "train = train[train['label']!=3]\n",
    "\n",
    "test = test[test['label']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d427ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Fakeddit                          0.626830\n",
       "Kaggle 1 - Fake News              0.264520\n",
       "Kaggle 2 - News Project           0.072445\n",
       "Kaggle 3 - Fake News Detection    0.022061\n",
       "LIAR 2                            0.014144\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "1    0.535523\n",
       "0    0.464477\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1122458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Some Descriptives\n",
    "\n",
    "display(train['dataset'].value_counts(normalize=True))\n",
    "display(train['binary_label'].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "\n",
    "display(len(test))\n",
    "display(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aca7928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for the first (and only) GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(f\"Memory growth enabled for {gpus[0]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)  # This happens if GPUs are initialized before setting memory growth\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9282ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "# Test-Validation Split\n",
    "train, val = train_test_split(train,test_size=0.3,random_state=42)#stratify=temp_train['dataset'])\n",
    "\n",
    "\n",
    "\n",
    "# Training data\n",
    "X_train = train['text'].values  \n",
    "y_train = train['binary_label'].values \n",
    "\n",
    "# Validation data\n",
    "X_val = val['text'].values\n",
    "y_val = val['binary_label'].values\n",
    "\n",
    "#Test data\n",
    "X_test = test['text'].values\n",
    "y_test = test['binary_label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceea84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [str(x) for x in X_train]\n",
    "X_val = [str(x) for x in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeedaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Fakeddit                          0.626927\n",
       "Kaggle 1 - Fake News              0.264514\n",
       "Kaggle 2 - News Project           0.072439\n",
       "Kaggle 3 - Fake News Detection    0.022148\n",
       "LIAR 2                            0.013972\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Fakeddit                          0.626788\n",
       "Kaggle 1 - Fake News              0.264523\n",
       "Kaggle 2 - News Project           0.072447\n",
       "Kaggle 3 - Fake News Detection    0.022024\n",
       "LIAR 2                            0.014218\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Kaggle 2 - News Project           0.206718\n",
       "Kaggle 3 - Fake News Detection    0.206718\n",
       "Fakeddit                          0.206718\n",
       "Kaggle 1 - Fake News              0.206718\n",
       "LIAR 2                            0.173127\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of datasets in training validation and test set\n",
    "# Test set is equally sampled as we wanted. LIAR 2 a bit less due to the removing of category 3\n",
    "\n",
    "display(val['dataset'].value_counts(normalize=True))\n",
    "\n",
    "display(train['dataset'].value_counts(normalize=True))\n",
    "\n",
    "display(test['dataset'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab370b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding = 'max_length',max_length=60, return_tensors=\"tf\")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    X_val,\n",
    "    truncation=True,\n",
    "    padding = 'max_length',\n",
    "    max_length = 60,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf219fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "inputs = {\n",
    "    'input_word_ids': train_encodings['input_ids'],\n",
    "    'input_mask': train_encodings['attention_mask'],\n",
    "    'input_type_ids': train_encodings['token_type_ids']\n",
    "}\n",
    "labels = tf.cast(y_train, tf.float32)\n",
    "\n",
    "\n",
    "val_inputs = {\n",
    "    'input_word_ids': val_encodings['input_ids'],\n",
    "    'input_mask': val_encodings['attention_mask'],\n",
    "    'input_type_ids': val_encodings['token_type_ids']\n",
    "}\n",
    "val_labels = tf.cast(y_val, tf.float32)\n",
    "\n",
    "\n",
    "# Now build dataset properly\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((inputs,  labels)).shuffle(buffer_size=len(X_train),seed=SEED).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_inputs, val_labels))\\\n",
    "         .batch(BATCH_SIZE)\\\n",
    "         .prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a1f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4050 Laptop GPU, compute capability 8.9\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_mask (InputLayer)        [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " input_word_ids (InputLayer)    [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'pooled_output': (  109482241   ['input_mask[0][0]',             \n",
      "                                None, 768),                       'input_type_ids[0][0]',         \n",
      "                                 'default': (None,                'input_word_ids[0][0]']         \n",
      "                                768),                                                             \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 60, 768),                                                \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768)],                                                \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 60, 768)}                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer[0][13]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# BERT encoder \n",
    "bert_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
    "    trainable=True\n",
    ")\n",
    "\n",
    "\n",
    "# Inputs\n",
    "input_ids = tf.keras.Input(shape=(60,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = tf.keras.Input(shape=(60,), dtype=tf.int32, name=\"input_mask\")\n",
    "type_ids = tf.keras.Input(shape=(60,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "\n",
    "bert_inputs = {\n",
    "    'input_word_ids': input_ids,\n",
    "    'input_mask': input_mask,\n",
    "    'input_type_ids': type_ids\n",
    "}\n",
    "\n",
    "bert_outputs = bert_model(bert_inputs)\n",
    "cls_token = bert_outputs['pooled_output']\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.1)(cls_token)\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask, type_ids], outputs=x)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b77c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(2e-5), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6311c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/StatefulPartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"mul_2:0\", dtype=float32), dense_shape=Tensor(\"Adam/gradients/StatefulPartitionedCall:2\", shape=(None,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49108/49108 [==============================] - 9283s 189ms/step - loss: 0.3113 - accuracy: 0.8666 - val_loss: 0.2768 - val_accuracy: 0.8845\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc09380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605/605 [==============================] - 51s 83ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.88      0.83      0.85      9932\n",
      "        Real       0.83      0.88      0.86      9418\n",
      "\n",
      "    accuracy                           0.86     19350\n",
      "   macro avg       0.86      0.86      0.86     19350\n",
      "weighted avg       0.86      0.86      0.86     19350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "X_test = [str(x) for x in X_test]\n",
    "\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding='max_length', max_length=60, return_tensors=\"tf\")\n",
    "\n",
    "# Prepare dataset\n",
    "inputs_test = {\n",
    "    'input_word_ids': test_encodings['input_ids'],\n",
    "    'input_mask': test_encodings['attention_mask'],\n",
    "    'input_type_ids': test_encodings['token_type_ids']\n",
    "}\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(dict(inputs_test))\n",
    "\n",
    "threshold = 0.5\n",
    "preds = (predictions>threshold).astype(int)\n",
    "\n",
    "print(classification_report(preds,y_test, target_names = ['Fake','Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cc19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Fakeddit                          0.858750\n",
       "Kaggle 1 - Fake News              0.965250\n",
       "Kaggle 2 - News Project           0.839750\n",
       "Kaggle 3 - Fake News Detection    0.881500\n",
       "LIAR 2                            0.706866\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy by dataset\n",
    "\n",
    "preds_new = pd.DataFrame(preds,index=test.index)\n",
    "concat = pd.concat([test,preds_new],axis=1)\n",
    "\n",
    "concat.columns.values[-1] = 'preds'\n",
    "\n",
    "concat['preds'].value_counts()\n",
    "\n",
    "accuracy_df = (concat['preds'] == concat['binary_label']).groupby(concat['dataset']).mean()\n",
    "\n",
    "accuracy_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848849f",
   "metadata": {},
   "source": [
    "## Testing on LLM-generated fake news ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749fe0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading LLM data\n",
    "with zipfile.ZipFile('llm_train_df.csv.zip','r') as zip:\n",
    "    with zip.open('llm_train_df.csv') as f:\n",
    "        llm_data = pd.read_csv(f,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04454289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = llm_data['text'].values\n",
    "y_test = llm_data['binary_label'].values \n",
    "\n",
    "X_test = [str(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9c1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding = 'max_length',max_length=60, return_tensors=\"tf\")\n",
    "\n",
    "inputs = {  'input_word_ids': test_encodings['input_ids'],\n",
    "            'input_mask': test_encodings['attention_mask'],\n",
    "            'input_type_ids': test_encodings['token_type_ids']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbaa79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11946/11946 [==============================] - 1038s 87ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.27      0.71      0.39    100279\n",
      "        Real       0.74      0.30      0.43    281968\n",
      "\n",
      "    accuracy                           0.41    382247\n",
      "   macro avg       0.51      0.51      0.41    382247\n",
      "weighted avg       0.62      0.41      0.42    382247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(inputs)\n",
    "\n",
    "threshold = 0.5\n",
    "preds = (preds>threshold).astype(int)\n",
    "\n",
    "print(classification_report(preds,y_test, target_names = ['Fake','Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d21902d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "GPT3.5        0.299480\n",
       "Llama2 13b    0.247443\n",
       "Llama2 7b     0.248331\n",
       "Mistral 7b    0.262976\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per model accuracy\n",
    "\n",
    "preds_new = pd.DataFrame(preds,index=llm_data.index)\n",
    "concat = pd.concat([llm_data,preds_new],axis=1)\n",
    "\n",
    "concat.columns.values[-1] = 'preds'\n",
    "\n",
    "concat['preds'].value_counts()\n",
    "\n",
    "accuracy_df = (concat['preds'] == concat['binary_label']).groupby(concat['model']).mean()\n",
    "\n",
    "accuracy_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
