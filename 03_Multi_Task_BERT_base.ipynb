{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f64f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reading datasets\n",
    "with zipfile.ZipFile('llm_train_df.csv.zip','r') as zip:\n",
    "    with zip.open('llm_train_df.csv') as f:\n",
    "        llm_data = pd.read_csv(f,encoding='ISO-8859-1')\n",
    "\n",
    "with zipfile.ZipFile('combined_train_df_2.csv.zip','r') as zip:\n",
    "    with zip.open('combined_train_df_2.csv') as f:\n",
    "        train = pd.read_csv(f,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea1f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for the first (and only) GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(f\"Memory growth enabled for {gpus[0]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)  # This happens if GPUs are initialized before setting memory growth\n",
    "else:\n",
    "    print(\"No GPU found. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13bd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_data['Human_vs_AI'] = llm_data.apply(lambda x: 0 if x['type']=='main' else 1,axis=1)\n",
    "train['Human_vs_AI'] = 0\n",
    "combined = pd.concat([llm_data,train],axis=0)\n",
    "\n",
    "# Remove LIAR 2 middle category\n",
    "combined = combined[combined['label']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83ecc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504705"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f9091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "0    0.525513\n",
       "1    0.474487\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Human_vs_AI\n",
       "0    0.814591\n",
       "1    0.185409\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Targets distributions\n",
    "\n",
    "display(combined['binary_label'].value_counts(normalize=True))\n",
    "display(combined['Human_vs_AI'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de349e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human_vs_AI\n",
       "0    0.605078\n",
       "1    0.394922\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "0    0.638499\n",
       "1    0.361501\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Oversampling minority\n",
    "\n",
    "minority = combined[combined['Human_vs_AI'] == 1]\n",
    "majority = combined[combined['Human_vs_AI'] == 0]\n",
    "\n",
    "\n",
    "minority_upsampled = resample(minority, \n",
    "                              replace=True,    # allow duplicates\n",
    "                              n_samples=800000, # match majority count\n",
    "                              random_state=42) # reproducible\n",
    "\n",
    "\n",
    "combined_balanced = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "display(combined_balanced['Human_vs_AI'].value_counts(normalize=True))\n",
    "display(combined_balanced['binary_label'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce98a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025719"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "\n",
    "\n",
    "# Test-Validation Split\n",
    "train, val = train_test_split(combined_balanced,test_size=0.3,random_state=42)#stratify=temp_train['dataset'])\n",
    "\n",
    "\n",
    "\n",
    "# Training data\n",
    "X_train = train['text'].values  \n",
    "y_train = {\n",
    "    'Fake_News_Output': train['binary_label'].values,\n",
    "    'Human_vs_AI': train['Human_vs_AI'].values\n",
    "} \n",
    "\n",
    "# Validation data\n",
    "X_val = val['text'].values\n",
    "val_train = {\n",
    "    'Fake_News_Output': val['binary_label'].values,\n",
    "    'Human_vs_AI': val['Human_vs_AI'].values\n",
    "} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5aac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [str(x) for x in X_train]\n",
    "X_val = [str(x) for x in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f2767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "LLM News Dataset                  0.445919\n",
       "Fakeddit                          0.347621\n",
       "Kaggle 1 - Fake News              0.146104\n",
       "Kaggle 2 - News Project           0.040266\n",
       "Kaggle 3 - Fake News Detection    0.012284\n",
       "LIAR 2                            0.007806\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "LLM News Dataset                  0.445887\n",
       "Fakeddit                          0.347203\n",
       "Kaggle 1 - Fake News              0.146772\n",
       "Kaggle 2 - News Project           0.040089\n",
       "Kaggle 3 - Fake News Detection    0.012199\n",
       "LIAR 2                            0.007850\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train and validation  distributions by dataset\n",
    "display(val['dataset'].value_counts(normalize=True))\n",
    "\n",
    "display(train['dataset'].value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding = 'max_length',max_length=60, return_tensors=\"tf\")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    X_val,\n",
    "    truncation=True,\n",
    "    padding = 'max_length',\n",
    "    max_length = 60,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "inputs = {\n",
    "    'input_word_ids': train_encodings['input_ids'],\n",
    "    'input_mask': train_encodings['attention_mask'],\n",
    "    'input_type_ids': train_encodings['token_type_ids']\n",
    "}\n",
    "\n",
    "\n",
    "val_inputs = {\n",
    "    'input_word_ids': val_encodings['input_ids'],\n",
    "    'input_mask': val_encodings['attention_mask'],\n",
    "    'input_type_ids': val_encodings['token_type_ids']\n",
    "}\n",
    "\n",
    "\n",
    "# Now build dataset properly\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((inputs,  y_train)).shuffle(buffer_size=len(X_train),seed=SEED).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_inputs, val_train))\\\n",
    "         .batch(BATCH_SIZE)\\\n",
    "         .prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00b8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4050 Laptop GPU, compute capability 8.9\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_mask (InputLayer)        [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " input_word_ids (InputLayer)    [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'encoder_outputs':  109482241   ['input_mask[0][0]',             \n",
      "                                 [(None, 60, 768),                'input_type_ids[0][0]',         \n",
      "                                 (None, 60, 768),                 'input_word_ids[0][0]']         \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 (None, 60, 768)],                                                \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 60, 768),                                                 \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768)}                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer[0][13]']           \n",
      "                                                                                                  \n",
      " Fake_News_Output (Dense)       (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Human_vs_AI (Dense)            (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,779\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# BERT encoder \n",
    "bert_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
    "    trainable=True\n",
    ")\n",
    "\n",
    "\n",
    "# Inputs\n",
    "input_ids = tf.keras.Input(shape=(60,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = tf.keras.Input(shape=(60,), dtype=tf.int32, name=\"input_mask\")\n",
    "type_ids = tf.keras.Input(shape=(60), dtype=tf.int32, name=\"input_type_ids\")\n",
    "\n",
    "bert_inputs = {\n",
    "    'input_word_ids': input_ids,\n",
    "    'input_mask': input_mask,\n",
    "    'input_type_ids': type_ids\n",
    "}\n",
    "\n",
    "bert_outputs = bert_model(bert_inputs)\n",
    "cls_token = bert_outputs['pooled_output']\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.1)(cls_token)\n",
    "\n",
    "# First classification head\n",
    "fake_news = tf.keras.layers.Dense(1,activation='sigmoid',name='Fake_News_Output',dtype=\"float32\")(x)\n",
    "\n",
    "# Second classification head\n",
    "human_ai = tf.keras.layers.Dense(1, activation='sigmoid', name='Human_vs_AI',dtype='float32')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask, type_ids], outputs=[fake_news,human_ai])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b0e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = {'Fake_News_Output':'binary_crossentropy', \n",
    "                      'Human_vs_AI': 'binary_crossentropy'}, \n",
    "                      optimizer = tf.keras.optimizers.Adam(2e-5),  \n",
    "                      metrics={'Fake_News_Output': 'accuracy',\n",
    "                               'Human_vs_AI': 'accuracy'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d8f511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\makri\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/StatefulPartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"mul_4:0\", dtype=float32), dense_shape=Tensor(\"Adam/gradients/StatefulPartitionedCall:2\", shape=(None,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88626/88626 [==============================] - 16991s 192ms/step - loss: 0.2831 - Fake_News_Output_loss: 0.2241 - Human_vs_AI_loss: 0.0590 - Fake_News_Output_accuracy: 0.9047 - Human_vs_AI_accuracy: 0.9779 - val_loss: 0.2628 - val_Fake_News_Output_loss: 0.2050 - val_Human_vs_AI_loss: 0.0578 - val_Fake_News_Output_accuracy: 0.9179 - val_Human_vs_AI_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d60c42",
   "metadata": {},
   "source": [
    "# Testing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51eebd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data \n",
    "with zipfile.ZipFile('llm_test_df.csv.zip','r') as zip:\n",
    "    with zip.open('llm_test_df.csv') as f:\n",
    "        llm_data_test = pd.read_csv(f,encoding='ISO-8859-1')\n",
    "\n",
    "with zipfile.ZipFile('test_df_2.csv.zip','r') as zip:\n",
    "    with zip.open('test_df_2.csv') as f:\n",
    "        test = pd.read_csv(f,encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33250ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_data_test['Human_vs_AI'] = llm_data_test.apply(lambda x: 0 if x['type']=='main' else 1,axis=1)\n",
    "test['Human_vs_AI'] = 0\n",
    "combined_test = pd.concat([llm_data_test,test],axis=0)\n",
    "\n",
    "# Remove LIAR 2 middle category\n",
    "combined_test = combined_test[combined_test['label']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17646701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "0    0.667293\n",
       "1    0.332707\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Human_vs_AI\n",
       "1    0.60696\n",
       "0    0.39304\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Targets distributions\n",
    "display(combined_test['binary_label'].value_counts(normalize=True))\n",
    "display(combined_test['Human_vs_AI'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60027e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "LLM News Dataset                  0.831610\n",
       "Kaggle 2 - News Project           0.034809\n",
       "Kaggle 3 - Fake News Detection    0.034809\n",
       "Fakeddit                          0.034809\n",
       "Kaggle 1 - Fake News              0.034809\n",
       "LIAR 2                            0.029153\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution by dataset\n",
    "display(combined_test['dataset'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68713574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human_vs_AI\n",
       "0    0.876317\n",
       "1    0.123683\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "0    0.519229\n",
       "1    0.480771\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "Kaggle 2 - News Project           0.171306\n",
       "Kaggle 3 - Fake News Detection    0.171306\n",
       "Fakeddit                          0.171306\n",
       "Kaggle 1 - Fake News              0.171306\n",
       "LLM News Dataset                  0.171306\n",
       "LIAR 2                            0.143469\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random 4000 samples from LLM dataset\n",
    "\n",
    "minority = combined_test[combined_test['dataset']!= 'LLM News Dataset']\n",
    "majority = combined_test[combined_test['dataset'] == 'LLM News Dataset']\n",
    "\n",
    "\n",
    "\n",
    "majority_downsampled = resample(majority, \n",
    "                              replace=True,    # allow duplicates\n",
    "                              n_samples=4000, # match majority count\n",
    "                              random_state=42) # reproducible\n",
    "\n",
    "\n",
    "combined_test_balanced = pd.concat([minority, majority_downsampled])\n",
    "\n",
    "display(combined_test_balanced['Human_vs_AI'].value_counts(normalize=True))\n",
    "display(combined_test_balanced['binary_label'].value_counts(normalize=True))\n",
    "\n",
    "display(combined_test_balanced['dataset'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e048555",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = combined_test_balanced['text'].values\n",
    "y_test = {\n",
    "    'Fake_News_Output': combined_test_balanced['binary_label'].values,\n",
    "    'Human_vs_AI': combined_test_balanced['Human_vs_AI'].values\n",
    "} \n",
    "\n",
    "X_test = [str(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aafb4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(X_test, truncation=True, padding = 'max_length',max_length=60, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26502b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730/730 [==============================] - 61s 82ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86     12741\n",
      "           1       0.81      0.86      0.84     10609\n",
      "\n",
      "    accuracy                           0.85     23350\n",
      "   macro avg       0.84      0.85      0.85     23350\n",
      "weighted avg       0.85      0.85      0.85     23350\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     19501\n",
      "           1       0.99      0.74      0.85      3849\n",
      "\n",
      "    accuracy                           0.96     23350\n",
      "   macro avg       0.97      0.87      0.91     23350\n",
      "weighted avg       0.96      0.96      0.95     23350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "inputs_test = {\n",
    "    'input_word_ids': test_encodings['input_ids'],\n",
    "    'input_mask': test_encodings['attention_mask'],\n",
    "    'input_type_ids': test_encodings['token_type_ids']\n",
    "}\n",
    "\n",
    "# Predictions fake news\n",
    "predictions = model.predict(dict(inputs_test))\n",
    "\n",
    "threshold = 0.5\n",
    "preds = (predictions[0]>threshold).astype(int)\n",
    "print(classification_report(preds,y_test[\"Fake_News_Output\"]))\n",
    "\n",
    "# Predictions Human-vs-AI\n",
    "preds_new = (predictions[1]>threshold).astype(int)\n",
    "print(classification_report(preds_new,y_test[\"Human_vs_AI\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b20b4f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preds\n",
       "0    12741\n",
       "1    10609\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "Fakeddit                          0.858750\n",
      "Kaggle 1 - Fake News              0.948250\n",
      "Kaggle 2 - News Project           0.784500\n",
      "Kaggle 3 - Fake News Detection    0.815750\n",
      "LIAR 2                            0.706567\n",
      "LLM News Dataset                  0.940250\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "preds\n",
       "0    19501\n",
       "1     3849\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "Fakeddit                          0.998500\n",
      "Kaggle 1 - Fake News              0.975000\n",
      "Kaggle 2 - News Project           0.941000\n",
      "Kaggle 3 - Fake News Detection    0.902500\n",
      "LIAR 2                            0.975522\n",
      "LLM News Dataset                  0.944750\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Per model accuracy (Fake news detection)\n",
    "preds_new_new = pd.DataFrame(preds,index=combined_test_balanced.index)\n",
    "concat = pd.concat([combined_test_balanced,preds_new_new],axis=1)\n",
    "\n",
    "concat.columns.values[-1] = 'preds'\n",
    "\n",
    "display(concat['preds'].value_counts())\n",
    "\n",
    "accuracy_df = (concat['preds'] == concat['binary_label']).groupby(concat['dataset']).mean()\n",
    "\n",
    "print(accuracy_df)\n",
    "\n",
    "\n",
    "# Per model accuracy (Human-vs-AI)\n",
    "preds_new_new = pd.DataFrame(preds_new,index=combined_test_balanced.index)\n",
    "concat = pd.concat([combined_test_balanced,preds_new_new],axis=1)\n",
    "\n",
    "concat.columns.values[-1] = 'preds'\n",
    "\n",
    "display(concat['preds'].value_counts())\n",
    "\n",
    "accuracy_df = (concat['preds'] == concat['Human_vs_AI']).groupby(concat['dataset']).mean()\n",
    "\n",
    "print(accuracy_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa94d244",
   "metadata": {},
   "source": [
    "# Now test only on LLM data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fefcd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binary_label\n",
       "0    0.704747\n",
       "1    0.295253\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Human_vs_AI\n",
       "1    0.729861\n",
       "0    0.270139\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(llm_data_test['binary_label'].value_counts(normalize=True))\n",
    "display(llm_data_test['Human_vs_AI'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26de422d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "GPT3.5        0.263590\n",
       "Mistral 7b    0.253345\n",
       "Llama2 7b     0.242966\n",
       "Llama2 13b    0.240100\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display models \n",
    "display(llm_data_test['model'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed139576",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = llm_data_test['text'].values\n",
    "y_test = {\n",
    "    'Fake_News_Output': llm_data_test['binary_label'].values,\n",
    "    'Human_vs_AI': llm_data_test['Human_vs_AI'].values\n",
    "} \n",
    "\n",
    "X_test = [str(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c7a0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(X_test, truncation=True, padding = 'max_length',max_length=60, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9660c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2987/2987 [==============================] - 252s 85ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     71382\n",
      "           1       0.83      0.97      0.89     24180\n",
      "\n",
      "    accuracy                           0.94     95562\n",
      "   macro avg       0.91      0.95      0.93     95562\n",
      "weighted avg       0.95      0.94      0.94     95562\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89     22327\n",
      "           1       0.99      0.94      0.96     73235\n",
      "\n",
      "    accuracy                           0.94     95562\n",
      "   macro avg       0.91      0.95      0.93     95562\n",
      "weighted avg       0.95      0.94      0.95     95562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "inputs_test = {\n",
    "    'input_word_ids': test_encodings['input_ids'],\n",
    "    'input_mask': test_encodings['attention_mask'],\n",
    "    'input_type_ids': test_encodings['token_type_ids']\n",
    "}\n",
    "\n",
    "# Predictions Fake News\n",
    "predictions = model.predict(dict(inputs_test))\n",
    "\n",
    "threshold = 0.5\n",
    "preds = (predictions[0]>threshold).astype(int)\n",
    "\n",
    "print(classification_report(preds,y_test[\"Fake_News_Output\"]))\n",
    "\n",
    "# Predictions Human vs AI\n",
    "preds_new = (predictions[1]>threshold).astype(int)\n",
    "\n",
    "print(classification_report(preds_new,y_test[\"Human_vs_AI\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afefbf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preds\n",
       "0    71382\n",
       "1    24180\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "GPT3.5        0.996676\n",
      "Llama2 13b    0.981447\n",
      "Llama2 7b     0.983744\n",
      "Mistral 7b    0.992146\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "preds\n",
       "1    73235\n",
       "0    22327\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "GPT3.5        0.996113\n",
      "Llama2 13b    0.980705\n",
      "Llama2 7b     0.982460\n",
      "Mistral 7b    0.990681\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Per model accuracy (Fake News Detection)\n",
    "preds_new_new = pd.DataFrame(preds,index=llm_data_test.index)\n",
    "concat = pd.concat([llm_data_test,preds_new_new],axis=1)\n",
    "\n",
    "concat.columns.values[-1] = 'preds'\n",
    "\n",
    "display(concat['preds'].value_counts())\n",
    "\n",
    "accuracy_df = (concat['preds'] == concat['binary_label']).groupby(concat['model']).mean()\n",
    "\n",
    "print(accuracy_df)\n",
    "\n",
    "\n",
    "# Per model  accuracy (Human_vs_AI)\n",
    "preds_new_new = pd.DataFrame(preds_new,index=llm_data_test.index)\n",
    "concat = pd.concat([llm_data_test,preds_new_new],axis=1)\n",
    "\n",
    "concat.columns.values[-1] = 'preds'\n",
    "\n",
    "display(concat['preds'].value_counts())\n",
    "\n",
    "accuracy_df = (concat['preds'] == concat['Human_vs_AI']).groupby(concat['model']).mean()\n",
    "\n",
    "print(accuracy_df)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
